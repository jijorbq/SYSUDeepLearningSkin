{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL,torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    folds=5\n",
    "    def __init__(self, root , num_classes,fold=0,training=False,n_augment=2):\n",
    "        self.data_path = []\n",
    "        self.sides =448\n",
    "        self.n_augment = max(n_augment , 4)\n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(size=(224, 224)),\n",
    "                transforms.RandomRotation(5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean= [0.6075306,0.49116918 ,0.46066117],std = [0.22603881, 0.21623525, 0.2191065 ])\n",
    "            ]\n",
    "            )\n",
    "        self.training = training\n",
    "        for label in range(num_classes):\n",
    "            self.data_dir = os.path.join(root,os.listdir(root)[label])\n",
    "            self.filename = os.listdir(self.data_dir)\n",
    "            l = len(self.filename)\n",
    "            inter = l//SkinDataset.folds\n",
    "            picked = list(range(inter* fold,inter * (fold+1))) if not training else list(range(0,inter*fold))+list(range(inter*(fold+1),l))\n",
    "\n",
    "            for i in picked:\n",
    "                file_path = os.path.join(self.data_dir , self.filename[i])\n",
    "#                 img = Image.open(fil)\n",
    "                self.data_path.append((file_path, label))\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        index %= len(self.data_path)\n",
    "        ddir , label = self.data_path[index]\n",
    "        img = Image.open(ddir)\n",
    "        imgmat = self.transform(img)\n",
    "#         if self.training:\n",
    "#             imgmat += torch.randn(3,self.sides,self.sides)/256\n",
    "        result = (imgmat, label)\n",
    "        del imgmat\n",
    "        del img\n",
    "        return result\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)*self.n_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592564017.628971\n",
      "./log/1592564017.628971/\n",
      "resnet50_0.1\n"
     ]
    }
   ],
   "source": [
    "# del training_dataloader\n",
    "batch_size = 128\n",
    "lr = 0.1\n",
    "suffix = '%f' % time.time()\n",
    "log_dir = './log/%s'% suffix +'/'\n",
    "EXPERIMENT = 'resnet50_%s'% str(lr)\n",
    "os.mkdir(log_dir)\n",
    "print(suffix)\n",
    "print(log_dir)\n",
    "print(EXPERIMENT)\n",
    "\n",
    "training_dataset = SkinDataset(os.path.join(os.getcwd(),'./Skin40'), 40, training=True)\n",
    "test_dataset = SkinDataset(os.path.join(os.getcwd(),'./Skin40'), 40)\n",
    "training_dataloader = DataLoader(training_dataset , batch_size = batch_size , num_workers = 1, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size = batch_size , num_workers = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, optimizer, device):\n",
    "    \"\"\"\n",
    "    train model using loss_fn and optimizer in an epoch.\n",
    "    model: CNN networks\n",
    "    train_loader: a Dataloader object with training data\n",
    "    loss_func: loss function\n",
    "    device: train on cpu or gpu device\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    # train the model using minibatch\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, targets)\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # every  iterations, print loss\n",
    "        if (i + 1) % (10) == 0:\n",
    "            print (\"Step [{}/{}] Train Loss: {:.4f}\"\n",
    "                   .format(i+1, len(train_loader), loss.item()))\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device, nclasses):\n",
    "    \"\"\"\n",
    "    model: CNN networks\n",
    "    val_loader: a Dataloader object with validation data\n",
    "    device: evaluate on cpu or gpu device\n",
    "    return classification accuracy of the model on val dataset\n",
    "    \"\"\"\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        cm = torch.zeros(nclasses, nclasses)\n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            # device: cpu or gpu\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            for t, p in zip(targets.view(-1), predicted.view(-1)):\n",
    "                cm[t.long()][p.long()] +=1\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "        accuracy = correct / total\n",
    "        print('Accuracy on Test Set: {:.4f} %'.format(100 * accuracy))\n",
    "        show_heatmap(cm, nclasses)\n",
    "        return accuracy,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_curve(ys, title):\n",
    "    \"\"\"\n",
    "    plot curlve for Loss and Accuacy\n",
    "    Args:\n",
    "        ys: loss or acc list\n",
    "        title: loss or accuracy\n",
    "    \"\"\"\n",
    "    x = np.array(range(len(ys)))\n",
    "    y = np.array(ys)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.axis()\n",
    "    plt.title('{} curve'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('{}'.format(title))\n",
    "    plt.show()\n",
    "\n",
    "def show_heatmap(cm, nclasses):\n",
    "    labels = range(nclasses)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_yticks(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xticks(labels)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    im = ax.imshow(cm, cmap=plt.cm.hot_r )\n",
    "    plt.colorbar(im)\n",
    "    plt.title(\"Confusioin Matrix\")\n",
    "    plt.show()\n",
    "    print('Accuracy of each class:\\n', cm.diag()/(cm.sum(1)+1e-6))\n",
    "    print('Recall of each class:\\n', cm.diag()/(cm.sum(0)+1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, optimizer, schedulr, device,nclasses):\n",
    "    \"\"\"\n",
    "     train and evaluate an classifier num_epochs times.\n",
    "    n and evaluate an classifier num_epochs times.\n",
    "    We use optimizer and cross entropy loss to train the model. \n",
    "    Args: \n",
    "        model: CNN network\n",
    "        num_epochs: the number of training epochs\n",
    "        optimizer: optimize the loss function    loss_func.to(device)\n",
    "    loss_func.to(device)\n",
    "        schedulr: scheduling learning rate\n",
    "\n",
    "    \"\"\"\n",
    "    # loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    # log train loss and test accuracy\n",
    "    losses = []\n",
    "    accs = []\n",
    "    cms = []\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}: , lr = {}'.format(epoch + 1, num_epochs , optimizer.param_groups[0]['lr']))\n",
    "        # train step\n",
    "        loss = train(model, training_dataloader, loss_func, optimizer, device)\n",
    "        losses.append(loss)\n",
    "        schedulr.step()\n",
    "        \n",
    "        # evaluate step\n",
    "        accuracy,cm = evaluate(model, test_dataloader, device,nclasses)\n",
    "        accs.append(accuracy)\n",
    "        cms.append(cm)\n",
    "        torch.save(cm,log_dir+str(epoch)+'_cms.pth')   \n",
    "        torch.save(loss,log_dir+str(epoch)+'_tls.pth')   \n",
    "        torch.save(accuracy,log_dir+str(epoch)+'_tas.pth')   \n",
    "    torch.save(cms,log_dir+EXPERIMENT+'_cms.pth')   \n",
    "    torch.save(losses,log_dir+EXPERIMENT+'_tls.pth')   \n",
    "    torch.save(accs,log_dir+EXPERIMENT+'_tas.pth')   \n",
    "    # show curve\n",
    "    show_curve(losses, \"train loss\")\n",
    "    show_curve(accs, \"test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResAttNet' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0b7aedcac3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptcv_get_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resattnet56'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResAttNet' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "net = ptcv_get_model(\"resnet18\", num_classes=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 40\n",
    "nclasses = 40\n",
    "feature_tune=False\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # optimizer\n",
    "#optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.1)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "schedulr = torch.optim.lr_scheduler.StepLR(optimizer , step_size = 2 , gamma = 0.5)\n",
    "for name,param in net.named_parameters():\n",
    "    print(param.requires_grad, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(net, num_epochs, optimizer, schedulr,device, nclasses)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
