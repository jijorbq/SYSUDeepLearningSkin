{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL,torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.models import resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    folds=5\n",
    "    def __init__(self, root , num_classes,fold=0,training=False,transform=None):\n",
    "        self.data_path = []\n",
    "        self.transform = transform\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(size=(224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "            )\n",
    "        for label in range(num_classes):\n",
    "            self.data_dir = os.path.join(root,os.listdir(root)[label])\n",
    "            self.filename = os.listdir(self.data_dir)\n",
    "            l = len(self.filename)\n",
    "            inter = l//SkinDataset.folds\n",
    "            picked = list(range(inter* fold,inter * (fold+1))) if not training else list(range(0,inter*fold))+list(range(inter*(fold+1),l))\n",
    "\n",
    "            for i in picked:\n",
    "                file_path = os.path.join(self.data_dir , self.filename[i])\n",
    "#                 img = Image.open(fil)\n",
    "                self.data_path.append((file_path, label))\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        ddir , label = self.data_path[index]\n",
    "        img = Image.open(ddir)\n",
    "        result = (self.transform(img) , label)\n",
    "        del img\n",
    "        return result\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4dbf21c7584e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem_len\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# image shape (3, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mnumpy_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'show'"
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6075306  0.49116918 0.46066117]\n",
      "[0.22603881 0.21623525 0.2191065 ]\n",
      "[0.22603923 0.2162355  0.21910688]\n"
>>>>>>> 5e7c188d2d2b8e6be06424a5418f802084d8a0fd
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "training_dataset0 = SkinDataset(os.path.join(os.getcwd(),'Skin40'), 40, training=True,transform=transform)\n",
    "test_dataset0 = SkinDataset(os.path.join(os.getcwd(),'Skin40'), 40, training=True,transform=transform)\n",
    "training_dataset1 = SkinDataset(os.path.join(os.getcwd(),'Skin40'), 40, training=False,transform=transform)\n",
    "test_dataset1 = SkinDataset(os.path.join(os.getcwd(),'Skin40'), 40, training=False,transform=transform)\n",
    "\n",
    "\n",
    "data_item = [training_dataset0,test_dataset0,training_dataset1,test_dataset1]\n",
    "\n",
    "pop_mean = []\n",
    "pop_std0 = []\n",
    "pop_std1 = []\n",
    "for data in data_item:\n",
    "    for item_len in range(data.__len__()):\n",
    "        image,_ = data.__getitem__(item_len)\n",
    "        # image shape (3, height, width)\n",
    "        numpy_image = image.numpy()\n",
<<<<<<< HEAD
    "\n",
    "        # shape (3,)\n",
    "        batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
    "        batch_std0 = np.std(numpy_image, axis=(0,2,3))\n",
    "        batch_std1 = np.std(numpy_image, axis=(0,2,3), ddof=1)\n",
=======
    "#        print(numpy_image)\n",
    "        # shape (3,)\n",
    "        batch_mean = np.mean(numpy_image, axis=(1,2))\n",
    "        batch_std0 = np.std(numpy_image, axis=(1,2))\n",
    "        batch_std1 = np.std(numpy_image, axis=(1,2), ddof=1)\n",
>>>>>>> 5e7c188d2d2b8e6be06424a5418f802084d8a0fd
    "\n",
    "        pop_mean.append(batch_mean)\n",
    "        pop_std0.append(batch_std0)\n",
    "        pop_std1.append(batch_std1)\n",
    "pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "pop_std0 = np.array(pop_std0).mean(axis=0)\n",
    "pop_std1 = np.array(pop_std1).mean(axis=0)\n",
    "\n",
    "# pop_mean , pop_std 在transforms.normalize()中直接使用\n",
    "print(pop_mean)\n",
    "print(pop_std0)\n",
    "print(pop_std1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于原始数据，大小不一致，而transform使用的resize，crop最终采用原始数据的哪一部分并不清楚（eg:左上，右下？）\n",
    "所以最终计算的是所有图片的整个图片的mean，std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
