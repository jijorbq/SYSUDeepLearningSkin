{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL,torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    folds=5\n",
    "    def __init__(self, root , num_classes,fold=0,training=False,transform=None):\n",
    "        self.data_path = []\n",
    "        self.transform = transform\n",
    "        self.sides = 224\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((self.sides,self.sides)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "            ])\n",
    "        self.training = training\n",
    "        for label in range(num_classes):\n",
    "            self.data_dir = os.path.join(root,os.listdir(root)[label])\n",
    "            self.filename = os.listdir(self.data_dir)\n",
    "            l = len(self.filename)\n",
    "            inter = l//SkinDataset.folds\n",
    "            picked = list(range(inter* fold,inter * (fold+1))) if not training else list(range(0,inter*fold))+list(range(inter*(fold+1),l))\n",
    "\n",
    "            for i in picked:\n",
    "                file_path = os.path.join(self.data_dir , self.filename[i])\n",
    "#                 img = Image.open(fil)\n",
    "                self.data_path.append((file_path, label))\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        ddir , label = self.data_path[index]\n",
    "        img = Image.open(ddir)\n",
    "        imgmat = self.transform(img)\n",
    "#         if self.training:\n",
    "#             imgmat += torch.randn(3,self.sides,self.sides)/256\n",
    "        result = (imgmat, label)\n",
    "        del imgmat\n",
    "        del img\n",
    "        return result\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del training_dataloader\n",
    "batch_size = 64\n",
    "training_dataset = SkinDataset(os.path.join(os.getcwd(),'../Skin40'), 40, training=True)\n",
    "test_dataset = SkinDataset(os.path.join(os.getcwd(),'../Skin40'), 40)\n",
    "training_dataloader = DataLoader(training_dataset , batch_size = batch_size , num_workers = 2, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size = batch_size , num_workers = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, optimizer, device):\n",
    "    \"\"\"\n",
    "    train model using loss_fn and optimizer in an epoch.\n",
    "    model: CNN networks\n",
    "    train_loader: a Dataloader object with training data\n",
    "    loss_func: loss function\n",
    "    device: train on cpu or gpu device\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    # train the model using minibatch\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, targets)\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # every 100 iteration, print loss\n",
    "        if (i + 1) % 6 == 0:\n",
    "            print (\"Step [{}/{}] Train Loss: {:.4f}\"\n",
    "                   .format(i+1, len(train_loader), loss.item()))\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device, nclasses):\n",
    "    \"\"\"\n",
    "    model: CNN networks\n",
    "    val_loader: a Dataloader object with validation data\n",
    "    device: evaluate on cpu or gpu device\n",
    "    return classification accuracy of the model on val dataset\n",
    "    \"\"\"\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        cm = torch.zeros(nclasses, nclasses)\n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            # device: cpu or gpu\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            for t, p in zip(targets.view(-1), predicted.view(-1)):\n",
    "                cm[t.long()][p.long()] +=1\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "        accuracy = correct / total\n",
    "        print('Accuracy on Test Set: {:.4f} %'.format(100 * accuracy))\n",
    "        show_heatmap(cm, nclasses)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_curve(ys, title):\n",
    "    \"\"\"\n",
    "    plot curlve for Loss and Accuacy\n",
    "    Args:\n",
    "        ys: loss or acc list\n",
    "        title: loss or accuracy\n",
    "    \"\"\"\n",
    "    x = np.array(range(len(ys)))\n",
    "    y = np.array(ys)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.axis()\n",
    "    plt.title('{} curve'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('{}'.format(title))\n",
    "    plt.show()\n",
    "\n",
    "def show_heatmap(cm, nclasses):\n",
    "    labels = range(nclasses)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_yticks(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xticks(labels)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    im = ax.imshow(cm, cmap=plt.cm.hot_r )\n",
    "    plt.colorbar(im)\n",
    "    plt.title(\"Confusioin Matrix\")\n",
    "    plt.show()\n",
    "    print('Accuracy of each class:\\n', cm.diag()/(cm.sum(1)+1e-6))\n",
    "    print('Recall of each class:\\n', cm.diag()/(cm.sum(0)+1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, optimizer, schedulr, device,nclasses):\n",
    "    \"\"\"\n",
    "     train and evaluate an classifier num_epochs times.\n",
    "    n and evaluate an classifier num_epochs times.\n",
    "    We use optimizer and cross entropy loss to train the model. \n",
    "    Args: \n",
    "        model: CNN network\n",
    "        num_epochs: the number of training epochs\n",
    "        optimizer: optimize the loss function    loss_func.to(device)\n",
    "    loss_func.to(device)\n",
    "        schedulr: scheduling learning rate\n",
    "\n",
    "    \"\"\"\n",
    "    # loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    # log train loss and test accuracy\n",
    "    losses = []\n",
    "    accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}: , lr = {}'.format(epoch + 1, num_epochs , optimizer.param_groups[0]['lr']))\n",
    "        # train step\n",
    "        loss = train(model, training_dataloader, loss_func, optimizer, device)\n",
    "        losses.append(loss)\n",
    "        schedulr.step()\n",
    "        \n",
    "        # evaluate step\n",
    "        accuracy = evaluate(model, test_dataloader, device,nclasses)\n",
    "        accs.append(accuracy)\n",
    "        \n",
    "    \n",
    "    # show curve\n",
    "    show_curve(losses, \"train loss\")\n",
    "    show_curve(accs, \"test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "net = EfficientNet.from_pretrained('efficientnet-b7')\n",
    "net._fc = torch.nn.Sequential(nn.Linear(2560, 4096),\n",
    "                             nn.ReLU(inplace=True),\n",
    "                             nn.Dropout(p=0.6),\n",
    "                             nn.Linear(4096, 4096),\n",
    "                             nn.ReLU(inplace=True),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(4096, 40)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2560, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net._fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True _conv_stem.weight\n",
      "True _bn0.weight\n",
      "True _bn0.bias\n",
      "True _blocks.0._depthwise_conv.weight\n",
      "True _blocks.0._bn1.weight\n",
      "True _blocks.0._bn1.bias\n",
      "True _blocks.0._se_reduce.weight\n",
      "True _blocks.0._se_reduce.bias\n",
      "True _blocks.0._se_expand.weight\n",
      "True _blocks.0._se_expand.bias\n",
      "True _blocks.0._project_conv.weight\n",
      "True _blocks.0._bn2.weight\n",
      "True _blocks.0._bn2.bias\n",
      "True _blocks.1._depthwise_conv.weight\n",
      "True _blocks.1._bn1.weight\n",
      "True _blocks.1._bn1.bias\n",
      "True _blocks.1._se_reduce.weight\n",
      "True _blocks.1._se_reduce.bias\n",
      "True _blocks.1._se_expand.weight\n",
      "True _blocks.1._se_expand.bias\n",
      "True _blocks.1._project_conv.weight\n",
      "True _blocks.1._bn2.weight\n",
      "True _blocks.1._bn2.bias\n",
      "True _blocks.2._depthwise_conv.weight\n",
      "True _blocks.2._bn1.weight\n",
      "True _blocks.2._bn1.bias\n",
      "True _blocks.2._se_reduce.weight\n",
      "True _blocks.2._se_reduce.bias\n",
      "True _blocks.2._se_expand.weight\n",
      "True _blocks.2._se_expand.bias\n",
      "True _blocks.2._project_conv.weight\n",
      "True _blocks.2._bn2.weight\n",
      "True _blocks.2._bn2.bias\n",
      "True _blocks.3._depthwise_conv.weight\n",
      "True _blocks.3._bn1.weight\n",
      "True _blocks.3._bn1.bias\n",
      "True _blocks.3._se_reduce.weight\n",
      "True _blocks.3._se_reduce.bias\n",
      "True _blocks.3._se_expand.weight\n",
      "True _blocks.3._se_expand.bias\n",
      "True _blocks.3._project_conv.weight\n",
      "True _blocks.3._bn2.weight\n",
      "True _blocks.3._bn2.bias\n",
      "True _blocks.4._expand_conv.weight\n",
      "True _blocks.4._bn0.weight\n",
      "True _blocks.4._bn0.bias\n",
      "True _blocks.4._depthwise_conv.weight\n",
      "True _blocks.4._bn1.weight\n",
      "True _blocks.4._bn1.bias\n",
      "True _blocks.4._se_reduce.weight\n",
      "True _blocks.4._se_reduce.bias\n",
      "True _blocks.4._se_expand.weight\n",
      "True _blocks.4._se_expand.bias\n",
      "True _blocks.4._project_conv.weight\n",
      "True _blocks.4._bn2.weight\n",
      "True _blocks.4._bn2.bias\n",
      "True _blocks.5._expand_conv.weight\n",
      "True _blocks.5._bn0.weight\n",
      "True _blocks.5._bn0.bias\n",
      "True _blocks.5._depthwise_conv.weight\n",
      "True _blocks.5._bn1.weight\n",
      "True _blocks.5._bn1.bias\n",
      "True _blocks.5._se_reduce.weight\n",
      "True _blocks.5._se_reduce.bias\n",
      "True _blocks.5._se_expand.weight\n",
      "True _blocks.5._se_expand.bias\n",
      "True _blocks.5._project_conv.weight\n",
      "True _blocks.5._bn2.weight\n",
      "True _blocks.5._bn2.bias\n",
      "True _blocks.6._expand_conv.weight\n",
      "True _blocks.6._bn0.weight\n",
      "True _blocks.6._bn0.bias\n",
      "True _blocks.6._depthwise_conv.weight\n",
      "True _blocks.6._bn1.weight\n",
      "True _blocks.6._bn1.bias\n",
      "True _blocks.6._se_reduce.weight\n",
      "True _blocks.6._se_reduce.bias\n",
      "True _blocks.6._se_expand.weight\n",
      "True _blocks.6._se_expand.bias\n",
      "True _blocks.6._project_conv.weight\n",
      "True _blocks.6._bn2.weight\n",
      "True _blocks.6._bn2.bias\n",
      "True _blocks.7._expand_conv.weight\n",
      "True _blocks.7._bn0.weight\n",
      "True _blocks.7._bn0.bias\n",
      "True _blocks.7._depthwise_conv.weight\n",
      "True _blocks.7._bn1.weight\n",
      "True _blocks.7._bn1.bias\n",
      "True _blocks.7._se_reduce.weight\n",
      "True _blocks.7._se_reduce.bias\n",
      "True _blocks.7._se_expand.weight\n",
      "True _blocks.7._se_expand.bias\n",
      "True _blocks.7._project_conv.weight\n",
      "True _blocks.7._bn2.weight\n",
      "True _blocks.7._bn2.bias\n",
      "True _blocks.8._expand_conv.weight\n",
      "True _blocks.8._bn0.weight\n",
      "True _blocks.8._bn0.bias\n",
      "True _blocks.8._depthwise_conv.weight\n",
      "True _blocks.8._bn1.weight\n",
      "True _blocks.8._bn1.bias\n",
      "True _blocks.8._se_reduce.weight\n",
      "True _blocks.8._se_reduce.bias\n",
      "True _blocks.8._se_expand.weight\n",
      "True _blocks.8._se_expand.bias\n",
      "True _blocks.8._project_conv.weight\n",
      "True _blocks.8._bn2.weight\n",
      "True _blocks.8._bn2.bias\n",
      "True _blocks.9._expand_conv.weight\n",
      "True _blocks.9._bn0.weight\n",
      "True _blocks.9._bn0.bias\n",
      "True _blocks.9._depthwise_conv.weight\n",
      "True _blocks.9._bn1.weight\n",
      "True _blocks.9._bn1.bias\n",
      "True _blocks.9._se_reduce.weight\n",
      "True _blocks.9._se_reduce.bias\n",
      "True _blocks.9._se_expand.weight\n",
      "True _blocks.9._se_expand.bias\n",
      "True _blocks.9._project_conv.weight\n",
      "True _blocks.9._bn2.weight\n",
      "True _blocks.9._bn2.bias\n",
      "True _blocks.10._expand_conv.weight\n",
      "True _blocks.10._bn0.weight\n",
      "True _blocks.10._bn0.bias\n",
      "True _blocks.10._depthwise_conv.weight\n",
      "True _blocks.10._bn1.weight\n",
      "True _blocks.10._bn1.bias\n",
      "True _blocks.10._se_reduce.weight\n",
      "True _blocks.10._se_reduce.bias\n",
      "True _blocks.10._se_expand.weight\n",
      "True _blocks.10._se_expand.bias\n",
      "True _blocks.10._project_conv.weight\n",
      "True _blocks.10._bn2.weight\n",
      "True _blocks.10._bn2.bias\n",
      "True _blocks.11._expand_conv.weight\n",
      "True _blocks.11._bn0.weight\n",
      "True _blocks.11._bn0.bias\n",
      "True _blocks.11._depthwise_conv.weight\n",
      "True _blocks.11._bn1.weight\n",
      "True _blocks.11._bn1.bias\n",
      "True _blocks.11._se_reduce.weight\n",
      "True _blocks.11._se_reduce.bias\n",
      "True _blocks.11._se_expand.weight\n",
      "True _blocks.11._se_expand.bias\n",
      "True _blocks.11._project_conv.weight\n",
      "True _blocks.11._bn2.weight\n",
      "True _blocks.11._bn2.bias\n",
      "True _blocks.12._expand_conv.weight\n",
      "True _blocks.12._bn0.weight\n",
      "True _blocks.12._bn0.bias\n",
      "True _blocks.12._depthwise_conv.weight\n",
      "True _blocks.12._bn1.weight\n",
      "True _blocks.12._bn1.bias\n",
      "True _blocks.12._se_reduce.weight\n",
      "True _blocks.12._se_reduce.bias\n",
      "True _blocks.12._se_expand.weight\n",
      "True _blocks.12._se_expand.bias\n",
      "True _blocks.12._project_conv.weight\n",
      "True _blocks.12._bn2.weight\n",
      "True _blocks.12._bn2.bias\n",
      "True _blocks.13._expand_conv.weight\n",
      "True _blocks.13._bn0.weight\n",
      "True _blocks.13._bn0.bias\n",
      "True _blocks.13._depthwise_conv.weight\n",
      "True _blocks.13._bn1.weight\n",
      "True _blocks.13._bn1.bias\n",
      "True _blocks.13._se_reduce.weight\n",
      "True _blocks.13._se_reduce.bias\n",
      "True _blocks.13._se_expand.weight\n",
      "True _blocks.13._se_expand.bias\n",
      "True _blocks.13._project_conv.weight\n",
      "True _blocks.13._bn2.weight\n",
      "True _blocks.13._bn2.bias\n",
      "True _blocks.14._expand_conv.weight\n",
      "True _blocks.14._bn0.weight\n",
      "True _blocks.14._bn0.bias\n",
      "True _blocks.14._depthwise_conv.weight\n",
      "True _blocks.14._bn1.weight\n",
      "True _blocks.14._bn1.bias\n",
      "True _blocks.14._se_reduce.weight\n",
      "True _blocks.14._se_reduce.bias\n",
      "True _blocks.14._se_expand.weight\n",
      "True _blocks.14._se_expand.bias\n",
      "True _blocks.14._project_conv.weight\n",
      "True _blocks.14._bn2.weight\n",
      "True _blocks.14._bn2.bias\n",
      "True _blocks.15._expand_conv.weight\n",
      "True _blocks.15._bn0.weight\n",
      "True _blocks.15._bn0.bias\n",
      "True _blocks.15._depthwise_conv.weight\n",
      "True _blocks.15._bn1.weight\n",
      "True _blocks.15._bn1.bias\n",
      "True _blocks.15._se_reduce.weight\n",
      "True _blocks.15._se_reduce.bias\n",
      "True _blocks.15._se_expand.weight\n",
      "True _blocks.15._se_expand.bias\n",
      "True _blocks.15._project_conv.weight\n",
      "True _blocks.15._bn2.weight\n",
      "True _blocks.15._bn2.bias\n",
      "True _blocks.16._expand_conv.weight\n",
      "True _blocks.16._bn0.weight\n",
      "True _blocks.16._bn0.bias\n",
      "True _blocks.16._depthwise_conv.weight\n",
      "True _blocks.16._bn1.weight\n",
      "True _blocks.16._bn1.bias\n",
      "True _blocks.16._se_reduce.weight\n",
      "True _blocks.16._se_reduce.bias\n",
      "True _blocks.16._se_expand.weight\n",
      "True _blocks.16._se_expand.bias\n",
      "True _blocks.16._project_conv.weight\n",
      "True _blocks.16._bn2.weight\n",
      "True _blocks.16._bn2.bias\n",
      "True _blocks.17._expand_conv.weight\n",
      "True _blocks.17._bn0.weight\n",
      "True _blocks.17._bn0.bias\n",
      "True _blocks.17._depthwise_conv.weight\n",
      "True _blocks.17._bn1.weight\n",
      "True _blocks.17._bn1.bias\n",
      "True _blocks.17._se_reduce.weight\n",
      "True _blocks.17._se_reduce.bias\n",
      "True _blocks.17._se_expand.weight\n",
      "True _blocks.17._se_expand.bias\n",
      "True _blocks.17._project_conv.weight\n",
      "True _blocks.17._bn2.weight\n",
      "True _blocks.17._bn2.bias\n",
      "True _blocks.18._expand_conv.weight\n",
      "True _blocks.18._bn0.weight\n",
      "True _blocks.18._bn0.bias\n",
      "True _blocks.18._depthwise_conv.weight\n",
      "True _blocks.18._bn1.weight\n",
      "True _blocks.18._bn1.bias\n",
      "True _blocks.18._se_reduce.weight\n",
      "True _blocks.18._se_reduce.bias\n",
      "True _blocks.18._se_expand.weight\n",
      "True _blocks.18._se_expand.bias\n",
      "True _blocks.18._project_conv.weight\n",
      "True _blocks.18._bn2.weight\n",
      "True _blocks.18._bn2.bias\n",
      "True _blocks.19._expand_conv.weight\n",
      "True _blocks.19._bn0.weight\n",
      "True _blocks.19._bn0.bias\n",
      "True _blocks.19._depthwise_conv.weight\n",
      "True _blocks.19._bn1.weight\n",
      "True _blocks.19._bn1.bias\n",
      "True _blocks.19._se_reduce.weight\n",
      "True _blocks.19._se_reduce.bias\n",
      "True _blocks.19._se_expand.weight\n",
      "True _blocks.19._se_expand.bias\n",
      "True _blocks.19._project_conv.weight\n",
      "True _blocks.19._bn2.weight\n",
      "True _blocks.19._bn2.bias\n",
      "True _blocks.20._expand_conv.weight\n",
      "True _blocks.20._bn0.weight\n",
      "True _blocks.20._bn0.bias\n",
      "True _blocks.20._depthwise_conv.weight\n",
      "True _blocks.20._bn1.weight\n",
      "True _blocks.20._bn1.bias\n",
      "True _blocks.20._se_reduce.weight\n",
      "True _blocks.20._se_reduce.bias\n",
      "True _blocks.20._se_expand.weight\n",
      "True _blocks.20._se_expand.bias\n",
      "True _blocks.20._project_conv.weight\n",
      "True _blocks.20._bn2.weight\n",
      "True _blocks.20._bn2.bias\n",
      "True _blocks.21._expand_conv.weight\n",
      "True _blocks.21._bn0.weight\n",
      "True _blocks.21._bn0.bias\n",
      "True _blocks.21._depthwise_conv.weight\n",
      "True _blocks.21._bn1.weight\n",
      "True _blocks.21._bn1.bias\n",
      "True _blocks.21._se_reduce.weight\n",
      "True _blocks.21._se_reduce.bias\n",
      "True _blocks.21._se_expand.weight\n",
      "True _blocks.21._se_expand.bias\n",
      "True _blocks.21._project_conv.weight\n",
      "True _blocks.21._bn2.weight\n",
      "True _blocks.21._bn2.bias\n",
      "True _blocks.22._expand_conv.weight\n",
      "True _blocks.22._bn0.weight\n",
      "True _blocks.22._bn0.bias\n",
      "True _blocks.22._depthwise_conv.weight\n",
      "True _blocks.22._bn1.weight\n",
      "True _blocks.22._bn1.bias\n",
      "True _blocks.22._se_reduce.weight\n",
      "True _blocks.22._se_reduce.bias\n",
      "True _blocks.22._se_expand.weight\n",
      "True _blocks.22._se_expand.bias\n",
      "True _blocks.22._project_conv.weight\n",
      "True _blocks.22._bn2.weight\n",
      "True _blocks.22._bn2.bias\n",
      "True _blocks.23._expand_conv.weight\n",
      "True _blocks.23._bn0.weight\n",
      "True _blocks.23._bn0.bias\n",
      "True _blocks.23._depthwise_conv.weight\n",
      "True _blocks.23._bn1.weight\n",
      "True _blocks.23._bn1.bias\n",
      "True _blocks.23._se_reduce.weight\n",
      "True _blocks.23._se_reduce.bias\n",
      "True _blocks.23._se_expand.weight\n",
      "True _blocks.23._se_expand.bias\n",
      "True _blocks.23._project_conv.weight\n",
      "True _blocks.23._bn2.weight\n",
      "True _blocks.23._bn2.bias\n",
      "True _blocks.24._expand_conv.weight\n",
      "True _blocks.24._bn0.weight\n",
      "True _blocks.24._bn0.bias\n",
      "True _blocks.24._depthwise_conv.weight\n",
      "True _blocks.24._bn1.weight\n",
      "True _blocks.24._bn1.bias\n",
      "True _blocks.24._se_reduce.weight\n",
      "True _blocks.24._se_reduce.bias\n",
      "True _blocks.24._se_expand.weight\n",
      "True _blocks.24._se_expand.bias\n",
      "True _blocks.24._project_conv.weight\n",
      "True _blocks.24._bn2.weight\n",
      "True _blocks.24._bn2.bias\n",
      "True _blocks.25._expand_conv.weight\n",
      "True _blocks.25._bn0.weight\n",
      "True _blocks.25._bn0.bias\n",
      "True _blocks.25._depthwise_conv.weight\n",
      "True _blocks.25._bn1.weight\n",
      "True _blocks.25._bn1.bias\n",
      "True _blocks.25._se_reduce.weight\n",
      "True _blocks.25._se_reduce.bias\n",
      "True _blocks.25._se_expand.weight\n",
      "True _blocks.25._se_expand.bias\n",
      "True _blocks.25._project_conv.weight\n",
      "True _blocks.25._bn2.weight\n",
      "True _blocks.25._bn2.bias\n",
      "True _blocks.26._expand_conv.weight\n",
      "True _blocks.26._bn0.weight\n",
      "True _blocks.26._bn0.bias\n",
      "True _blocks.26._depthwise_conv.weight\n",
      "True _blocks.26._bn1.weight\n",
      "True _blocks.26._bn1.bias\n",
      "True _blocks.26._se_reduce.weight\n",
      "True _blocks.26._se_reduce.bias\n",
      "True _blocks.26._se_expand.weight\n",
      "True _blocks.26._se_expand.bias\n",
      "True _blocks.26._project_conv.weight\n",
      "True _blocks.26._bn2.weight\n",
      "True _blocks.26._bn2.bias\n",
      "True _blocks.27._expand_conv.weight\n",
      "True _blocks.27._bn0.weight\n",
      "True _blocks.27._bn0.bias\n",
      "True _blocks.27._depthwise_conv.weight\n",
      "True _blocks.27._bn1.weight\n",
      "True _blocks.27._bn1.bias\n",
      "True _blocks.27._se_reduce.weight\n",
      "True _blocks.27._se_reduce.bias\n",
      "True _blocks.27._se_expand.weight\n",
      "True _blocks.27._se_expand.bias\n",
      "True _blocks.27._project_conv.weight\n",
      "True _blocks.27._bn2.weight\n",
      "True _blocks.27._bn2.bias\n",
      "True _blocks.28._expand_conv.weight\n",
      "True _blocks.28._bn0.weight\n",
      "True _blocks.28._bn0.bias\n",
      "True _blocks.28._depthwise_conv.weight\n",
      "True _blocks.28._bn1.weight\n",
      "True _blocks.28._bn1.bias\n",
      "True _blocks.28._se_reduce.weight\n",
      "True _blocks.28._se_reduce.bias\n",
      "True _blocks.28._se_expand.weight\n",
      "True _blocks.28._se_expand.bias\n",
      "True _blocks.28._project_conv.weight\n",
      "True _blocks.28._bn2.weight\n",
      "True _blocks.28._bn2.bias\n",
      "True _blocks.29._expand_conv.weight\n",
      "True _blocks.29._bn0.weight\n",
      "True _blocks.29._bn0.bias\n",
      "True _blocks.29._depthwise_conv.weight\n",
      "True _blocks.29._bn1.weight\n",
      "True _blocks.29._bn1.bias\n",
      "True _blocks.29._se_reduce.weight\n",
      "True _blocks.29._se_reduce.bias\n",
      "True _blocks.29._se_expand.weight\n",
      "True _blocks.29._se_expand.bias\n",
      "True _blocks.29._project_conv.weight\n",
      "True _blocks.29._bn2.weight\n",
      "True _blocks.29._bn2.bias\n",
      "True _blocks.30._expand_conv.weight\n",
      "True _blocks.30._bn0.weight\n",
      "True _blocks.30._bn0.bias\n",
      "True _blocks.30._depthwise_conv.weight\n",
      "True _blocks.30._bn1.weight\n",
      "True _blocks.30._bn1.bias\n",
      "True _blocks.30._se_reduce.weight\n",
      "True _blocks.30._se_reduce.bias\n",
      "True _blocks.30._se_expand.weight\n",
      "True _blocks.30._se_expand.bias\n",
      "True _blocks.30._project_conv.weight\n",
      "True _blocks.30._bn2.weight\n",
      "True _blocks.30._bn2.bias\n",
      "True _blocks.31._expand_conv.weight\n",
      "True _blocks.31._bn0.weight\n",
      "True _blocks.31._bn0.bias\n",
      "True _blocks.31._depthwise_conv.weight\n",
      "True _blocks.31._bn1.weight\n",
      "True _blocks.31._bn1.bias\n",
      "True _blocks.31._se_reduce.weight\n",
      "True _blocks.31._se_reduce.bias\n",
      "True _blocks.31._se_expand.weight\n",
      "True _blocks.31._se_expand.bias\n",
      "True _blocks.31._project_conv.weight\n",
      "True _blocks.31._bn2.weight\n",
      "True _blocks.31._bn2.bias\n",
      "True _blocks.32._expand_conv.weight\n",
      "True _blocks.32._bn0.weight\n",
      "True _blocks.32._bn0.bias\n",
      "True _blocks.32._depthwise_conv.weight\n",
      "True _blocks.32._bn1.weight\n",
      "True _blocks.32._bn1.bias\n",
      "True _blocks.32._se_reduce.weight\n",
      "True _blocks.32._se_reduce.bias\n",
      "True _blocks.32._se_expand.weight\n",
      "True _blocks.32._se_expand.bias\n",
      "True _blocks.32._project_conv.weight\n",
      "True _blocks.32._bn2.weight\n",
      "True _blocks.32._bn2.bias\n",
      "True _blocks.33._expand_conv.weight\n",
      "True _blocks.33._bn0.weight\n",
      "True _blocks.33._bn0.bias\n",
      "True _blocks.33._depthwise_conv.weight\n",
      "True _blocks.33._bn1.weight\n",
      "True _blocks.33._bn1.bias\n",
      "True _blocks.33._se_reduce.weight\n",
      "True _blocks.33._se_reduce.bias\n",
      "True _blocks.33._se_expand.weight\n",
      "True _blocks.33._se_expand.bias\n",
      "True _blocks.33._project_conv.weight\n",
      "True _blocks.33._bn2.weight\n",
      "True _blocks.33._bn2.bias\n",
      "True _blocks.34._expand_conv.weight\n",
      "True _blocks.34._bn0.weight\n",
      "True _blocks.34._bn0.bias\n",
      "True _blocks.34._depthwise_conv.weight\n",
      "True _blocks.34._bn1.weight\n",
      "True _blocks.34._bn1.bias\n",
      "True _blocks.34._se_reduce.weight\n",
      "True _blocks.34._se_reduce.bias\n",
      "True _blocks.34._se_expand.weight\n",
      "True _blocks.34._se_expand.bias\n",
      "True _blocks.34._project_conv.weight\n",
      "True _blocks.34._bn2.weight\n",
      "True _blocks.34._bn2.bias\n",
      "True _blocks.35._expand_conv.weight\n",
      "True _blocks.35._bn0.weight\n",
      "True _blocks.35._bn0.bias\n",
      "True _blocks.35._depthwise_conv.weight\n",
      "True _blocks.35._bn1.weight\n",
      "True _blocks.35._bn1.bias\n",
      "True _blocks.35._se_reduce.weight\n",
      "True _blocks.35._se_reduce.bias\n",
      "True _blocks.35._se_expand.weight\n",
      "True _blocks.35._se_expand.bias\n",
      "True _blocks.35._project_conv.weight\n",
      "True _blocks.35._bn2.weight\n",
      "True _blocks.35._bn2.bias\n",
      "True _blocks.36._expand_conv.weight\n",
      "True _blocks.36._bn0.weight\n",
      "True _blocks.36._bn0.bias\n",
      "True _blocks.36._depthwise_conv.weight\n",
      "True _blocks.36._bn1.weight\n",
      "True _blocks.36._bn1.bias\n",
      "True _blocks.36._se_reduce.weight\n",
      "True _blocks.36._se_reduce.bias\n",
      "True _blocks.36._se_expand.weight\n",
      "True _blocks.36._se_expand.bias\n",
      "True _blocks.36._project_conv.weight\n",
      "True _blocks.36._bn2.weight\n",
      "True _blocks.36._bn2.bias\n",
      "True _blocks.37._expand_conv.weight\n",
      "True _blocks.37._bn0.weight\n",
      "True _blocks.37._bn0.bias\n",
      "True _blocks.37._depthwise_conv.weight\n",
      "True _blocks.37._bn1.weight\n",
      "True _blocks.37._bn1.bias\n",
      "True _blocks.37._se_reduce.weight\n",
      "True _blocks.37._se_reduce.bias\n",
      "True _blocks.37._se_expand.weight\n",
      "True _blocks.37._se_expand.bias\n",
      "True _blocks.37._project_conv.weight\n",
      "True _blocks.37._bn2.weight\n",
      "True _blocks.37._bn2.bias\n",
      "True _blocks.38._expand_conv.weight\n",
      "True _blocks.38._bn0.weight\n",
      "True _blocks.38._bn0.bias\n",
      "True _blocks.38._depthwise_conv.weight\n",
      "True _blocks.38._bn1.weight\n",
      "True _blocks.38._bn1.bias\n",
      "True _blocks.38._se_reduce.weight\n",
      "True _blocks.38._se_reduce.bias\n",
      "True _blocks.38._se_expand.weight\n",
      "True _blocks.38._se_expand.bias\n",
      "True _blocks.38._project_conv.weight\n",
      "True _blocks.38._bn2.weight\n",
      "True _blocks.38._bn2.bias\n",
      "True _blocks.39._expand_conv.weight\n",
      "True _blocks.39._bn0.weight\n",
      "True _blocks.39._bn0.bias\n",
      "True _blocks.39._depthwise_conv.weight\n",
      "True _blocks.39._bn1.weight\n",
      "True _blocks.39._bn1.bias\n",
      "True _blocks.39._se_reduce.weight\n",
      "True _blocks.39._se_reduce.bias\n",
      "True _blocks.39._se_expand.weight\n",
      "True _blocks.39._se_expand.bias\n",
      "True _blocks.39._project_conv.weight\n",
      "True _blocks.39._bn2.weight\n",
      "True _blocks.39._bn2.bias\n",
      "True _blocks.40._expand_conv.weight\n",
      "True _blocks.40._bn0.weight\n",
      "True _blocks.40._bn0.bias\n",
      "True _blocks.40._depthwise_conv.weight\n",
      "True _blocks.40._bn1.weight\n",
      "True _blocks.40._bn1.bias\n",
      "True _blocks.40._se_reduce.weight\n",
      "True _blocks.40._se_reduce.bias\n",
      "True _blocks.40._se_expand.weight\n",
      "True _blocks.40._se_expand.bias\n",
      "True _blocks.40._project_conv.weight\n",
      "True _blocks.40._bn2.weight\n",
      "True _blocks.40._bn2.bias\n",
      "True _blocks.41._expand_conv.weight\n",
      "True _blocks.41._bn0.weight\n",
      "True _blocks.41._bn0.bias\n",
      "True _blocks.41._depthwise_conv.weight\n",
      "True _blocks.41._bn1.weight\n",
      "True _blocks.41._bn1.bias\n",
      "True _blocks.41._se_reduce.weight\n",
      "True _blocks.41._se_reduce.bias\n",
      "True _blocks.41._se_expand.weight\n",
      "True _blocks.41._se_expand.bias\n",
      "True _blocks.41._project_conv.weight\n",
      "True _blocks.41._bn2.weight\n",
      "True _blocks.41._bn2.bias\n",
      "True _blocks.42._expand_conv.weight\n",
      "True _blocks.42._bn0.weight\n",
      "True _blocks.42._bn0.bias\n",
      "True _blocks.42._depthwise_conv.weight\n",
      "True _blocks.42._bn1.weight\n",
      "True _blocks.42._bn1.bias\n",
      "True _blocks.42._se_reduce.weight\n",
      "True _blocks.42._se_reduce.bias\n",
      "True _blocks.42._se_expand.weight\n",
      "True _blocks.42._se_expand.bias\n",
      "True _blocks.42._project_conv.weight\n",
      "True _blocks.42._bn2.weight\n",
      "True _blocks.42._bn2.bias\n",
      "True _blocks.43._expand_conv.weight\n",
      "True _blocks.43._bn0.weight\n",
      "True _blocks.43._bn0.bias\n",
      "True _blocks.43._depthwise_conv.weight\n",
      "True _blocks.43._bn1.weight\n",
      "True _blocks.43._bn1.bias\n",
      "True _blocks.43._se_reduce.weight\n",
      "True _blocks.43._se_reduce.bias\n",
      "True _blocks.43._se_expand.weight\n",
      "True _blocks.43._se_expand.bias\n",
      "True _blocks.43._project_conv.weight\n",
      "True _blocks.43._bn2.weight\n",
      "True _blocks.43._bn2.bias\n",
      "True _blocks.44._expand_conv.weight\n",
      "True _blocks.44._bn0.weight\n",
      "True _blocks.44._bn0.bias\n",
      "True _blocks.44._depthwise_conv.weight\n",
      "True _blocks.44._bn1.weight\n",
      "True _blocks.44._bn1.bias\n",
      "True _blocks.44._se_reduce.weight\n",
      "True _blocks.44._se_reduce.bias\n",
      "True _blocks.44._se_expand.weight\n",
      "True _blocks.44._se_expand.bias\n",
      "True _blocks.44._project_conv.weight\n",
      "True _blocks.44._bn2.weight\n",
      "True _blocks.44._bn2.bias\n",
      "True _blocks.45._expand_conv.weight\n",
      "True _blocks.45._bn0.weight\n",
      "True _blocks.45._bn0.bias\n",
      "True _blocks.45._depthwise_conv.weight\n",
      "True _blocks.45._bn1.weight\n",
      "True _blocks.45._bn1.bias\n",
      "True _blocks.45._se_reduce.weight\n",
      "True _blocks.45._se_reduce.bias\n",
      "True _blocks.45._se_expand.weight\n",
      "True _blocks.45._se_expand.bias\n",
      "True _blocks.45._project_conv.weight\n",
      "True _blocks.45._bn2.weight\n",
      "True _blocks.45._bn2.bias\n",
      "True _blocks.46._expand_conv.weight\n",
      "True _blocks.46._bn0.weight\n",
      "True _blocks.46._bn0.bias\n",
      "True _blocks.46._depthwise_conv.weight\n",
      "True _blocks.46._bn1.weight\n",
      "True _blocks.46._bn1.bias\n",
      "True _blocks.46._se_reduce.weight\n",
      "True _blocks.46._se_reduce.bias\n",
      "True _blocks.46._se_expand.weight\n",
      "True _blocks.46._se_expand.bias\n",
      "True _blocks.46._project_conv.weight\n",
      "True _blocks.46._bn2.weight\n",
      "True _blocks.46._bn2.bias\n",
      "True _blocks.47._expand_conv.weight\n",
      "True _blocks.47._bn0.weight\n",
      "True _blocks.47._bn0.bias\n",
      "True _blocks.47._depthwise_conv.weight\n",
      "True _blocks.47._bn1.weight\n",
      "True _blocks.47._bn1.bias\n",
      "True _blocks.47._se_reduce.weight\n",
      "True _blocks.47._se_reduce.bias\n",
      "True _blocks.47._se_expand.weight\n",
      "True _blocks.47._se_expand.bias\n",
      "True _blocks.47._project_conv.weight\n",
      "True _blocks.47._bn2.weight\n",
      "True _blocks.47._bn2.bias\n",
      "True _blocks.48._expand_conv.weight\n",
      "True _blocks.48._bn0.weight\n",
      "True _blocks.48._bn0.bias\n",
      "True _blocks.48._depthwise_conv.weight\n",
      "True _blocks.48._bn1.weight\n",
      "True _blocks.48._bn1.bias\n",
      "True _blocks.48._se_reduce.weight\n",
      "True _blocks.48._se_reduce.bias\n",
      "True _blocks.48._se_expand.weight\n",
      "True _blocks.48._se_expand.bias\n",
      "True _blocks.48._project_conv.weight\n",
      "True _blocks.48._bn2.weight\n",
      "True _blocks.48._bn2.bias\n",
      "True _blocks.49._expand_conv.weight\n",
      "True _blocks.49._bn0.weight\n",
      "True _blocks.49._bn0.bias\n",
      "True _blocks.49._depthwise_conv.weight\n",
      "True _blocks.49._bn1.weight\n",
      "True _blocks.49._bn1.bias\n",
      "True _blocks.49._se_reduce.weight\n",
      "True _blocks.49._se_reduce.bias\n",
      "True _blocks.49._se_expand.weight\n",
      "True _blocks.49._se_expand.bias\n",
      "True _blocks.49._project_conv.weight\n",
      "True _blocks.49._bn2.weight\n",
      "True _blocks.49._bn2.bias\n",
      "True _blocks.50._expand_conv.weight\n",
      "True _blocks.50._bn0.weight\n",
      "True _blocks.50._bn0.bias\n",
      "True _blocks.50._depthwise_conv.weight\n",
      "True _blocks.50._bn1.weight\n",
      "True _blocks.50._bn1.bias\n",
      "True _blocks.50._se_reduce.weight\n",
      "True _blocks.50._se_reduce.bias\n",
      "True _blocks.50._se_expand.weight\n",
      "True _blocks.50._se_expand.bias\n",
      "True _blocks.50._project_conv.weight\n",
      "True _blocks.50._bn2.weight\n",
      "True _blocks.50._bn2.bias\n",
      "True _blocks.51._expand_conv.weight\n",
      "True _blocks.51._bn0.weight\n",
      "True _blocks.51._bn0.bias\n",
      "True _blocks.51._depthwise_conv.weight\n",
      "True _blocks.51._bn1.weight\n",
      "True _blocks.51._bn1.bias\n",
      "True _blocks.51._se_reduce.weight\n",
      "True _blocks.51._se_reduce.bias\n",
      "True _blocks.51._se_expand.weight\n",
      "True _blocks.51._se_expand.bias\n",
      "True _blocks.51._project_conv.weight\n",
      "True _blocks.51._bn2.weight\n",
      "True _blocks.51._bn2.bias\n",
      "True _blocks.52._expand_conv.weight\n",
      "True _blocks.52._bn0.weight\n",
      "True _blocks.52._bn0.bias\n",
      "True _blocks.52._depthwise_conv.weight\n",
      "True _blocks.52._bn1.weight\n",
      "True _blocks.52._bn1.bias\n",
      "True _blocks.52._se_reduce.weight\n",
      "True _blocks.52._se_reduce.bias\n",
      "True _blocks.52._se_expand.weight\n",
      "True _blocks.52._se_expand.bias\n",
      "True _blocks.52._project_conv.weight\n",
      "True _blocks.52._bn2.weight\n",
      "True _blocks.52._bn2.bias\n",
      "True _blocks.53._expand_conv.weight\n",
      "True _blocks.53._bn0.weight\n",
      "True _blocks.53._bn0.bias\n",
      "True _blocks.53._depthwise_conv.weight\n",
      "True _blocks.53._bn1.weight\n",
      "True _blocks.53._bn1.bias\n",
      "True _blocks.53._se_reduce.weight\n",
      "True _blocks.53._se_reduce.bias\n",
      "True _blocks.53._se_expand.weight\n",
      "True _blocks.53._se_expand.bias\n",
      "True _blocks.53._project_conv.weight\n",
      "True _blocks.53._bn2.weight\n",
      "True _blocks.53._bn2.bias\n",
      "True _blocks.54._expand_conv.weight\n",
      "True _blocks.54._bn0.weight\n",
      "True _blocks.54._bn0.bias\n",
      "True _blocks.54._depthwise_conv.weight\n",
      "True _blocks.54._bn1.weight\n",
      "True _blocks.54._bn1.bias\n",
      "True _blocks.54._se_reduce.weight\n",
      "True _blocks.54._se_reduce.bias\n",
      "True _blocks.54._se_expand.weight\n",
      "True _blocks.54._se_expand.bias\n",
      "True _blocks.54._project_conv.weight\n",
      "True _blocks.54._bn2.weight\n",
      "True _blocks.54._bn2.bias\n",
      "True _conv_head.weight\n",
      "True _bn1.weight\n",
      "True _bn1.bias\n",
      "True _fc.0.weight\n",
      "True _fc.0.bias\n",
      "True _fc.3.weight\n",
      "True _fc.3.bias\n",
      "True _fc.6.weight\n",
      "True _fc.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 50\n",
    "lr =1e-4\n",
    "nclasses = 40\n",
    "feature_tune=True\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "for parma in net.parameters():\n",
    "    parma.requires_grad = feature_tune\n",
    "for param in net._fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# # optimizer\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "schedulr = torch.optim.lr_scheduler.StepLR(optimizer , step_size = 2 , gamma = 0.83)\n",
    "for name,param in net.named_parameters():\n",
    "    print(param.requires_grad, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: , lr = 0.0001\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 1; 31.75 GiB total capacity; 18.24 GiB already allocated; 35.19 MiB free; 18.42 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f33bc8219cb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedulr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-fa883684184c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, num_epochs, optimizer, schedulr, device, nclasses)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}/{}: , lr = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# train step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mschedulr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8f02bee059cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_func, optimizer, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EfficientNet-PyTorch/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Pooling and final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EfficientNet-PyTorch/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \"\"\"\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Stem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# Blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/EfficientNet-PyTorch/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/padding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   2860\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding length too large'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2862\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_pad_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2863\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding mode \"{}\"\" doesn\\'t take in value argument'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 1; 31.75 GiB total capacity; 18.24 GiB already allocated; 35.19 MiB free; 18.42 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "fit(net, num_epochs, optimizer, schedulr,device, nclasses)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
