{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL,torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.models import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    folds=5\n",
    "    def __init__(self, root , num_classes,fold=0,training=False,transform=None):\n",
    "        self.data_path = []\n",
    "        self.transform = transform\n",
    "        self.sides = 112\n",
    "        if self.transform is None:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize((self.sides,self.sides)),\n",
    "                transforms.RandomRotation(5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "            ])\n",
    "        self.training = training\n",
    "        for label in range(num_classes):\n",
    "            self.data_dir = os.path.join(root,os.listdir(root)[label])\n",
    "            self.filename = os.listdir(self.data_dir)\n",
    "            l = len(self.filename)\n",
    "            inter = l//SkinDataset.folds\n",
    "            picked = list(range(inter* fold,inter * (fold+1))) if not training else list(range(0,inter*fold))+list(range(inter*(fold+1),l))\n",
    "\n",
    "            for i in picked:\n",
    "                file_path = os.path.join(self.data_dir , self.filename[i])\n",
    "#                 img = Image.open(fil)\n",
    "                self.data_path.append((file_path, label))\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        ddir , label = self.data_path[index]\n",
    "        img = Image.open(ddir)\n",
    "        imgmat = self.transform(img)\n",
    "        if self.training:\n",
    "            imgmat += torch.randn(3,self.sides,self.sides)/256\n",
    "        result = (imgmat, label)\n",
    "        del imgmat\n",
    "        del img\n",
    "        return result\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del training_dataloader\n",
    "batch_size = 64\n",
    "training_dataset = SkinDataset(os.path.join(os.getcwd(),'../Skin40'), 40, training=True)\n",
    "test_dataset = SkinDataset(os.path.join(os.getcwd(),'../Skin40'), 40)\n",
    "training_dataloader = DataLoader(training_dataset , batch_size = batch_size , num_workers = 1, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset , batch_size = batch_size , num_workers = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, optimizer, device):\n",
    "    \"\"\"\n",
    "    train model using loss_fn and optimizer in an epoch.\n",
    "    model: CNN networks\n",
    "    train_loader: a Dataloader object with training data\n",
    "    loss_func: loss function\n",
    "    device: train on cpu or gpu device\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    # train the model using minibatch\n",
    "    for i, (images, targets) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = loss_func(outputs, targets)\n",
    "\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # every 100 iteration, print loss\n",
    "        if (i + 1) % 6 == 0:\n",
    "            print (\"Step [{}/{}] Train Loss: {:.4f}\"\n",
    "                   .format(i+1, len(train_loader), loss.item()))\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, device, nclasses):\n",
    "    \"\"\"\n",
    "    model: CNN networks\n",
    "    val_loader: a Dataloader object with validation data\n",
    "    device: evaluate on cpu or gpu device\n",
    "    return classification accuracy of the model on val dataset\n",
    "    \"\"\"\n",
    "    # evaluate the model\n",
    "    model.eval()\n",
    "    # context-manager that disabled gradient computation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        cm = torch.zeros(nclasses, nclasses)\n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            # device: cpu or gpu\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            for t, p in zip(targets.view(-1), predicted.view(-1)):\n",
    "                cm[t.long()][p.long()] +=1\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "        accuracy = correct / total\n",
    "        print('Accuracy on Test Set: {:.4f} %'.format(100 * accuracy))\n",
    "        show_heatmap(cm, nclasses)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_curve(ys, title):\n",
    "    \"\"\"\n",
    "    plot curlve for Loss and Accuacy\n",
    "    Args:\n",
    "        ys: loss or acc list\n",
    "        title: loss or accuracy\n",
    "    \"\"\"\n",
    "    x = np.array(range(len(ys)))\n",
    "    y = np.array(ys)\n",
    "    plt.plot(x, y, c='b')\n",
    "    plt.axis()\n",
    "    plt.title('{} curve'.format(title))\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('{}'.format(title))\n",
    "    plt.show()\n",
    "\n",
    "def show_heatmap(cm, nclasses):\n",
    "    labels = range(nclasses)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_yticks(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xticks(labels)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    im = ax.imshow(cm, cmap=plt.cm.hot_r )\n",
    "    plt.colorbar(im)\n",
    "    plt.title(\"Confusioin Matrix\")\n",
    "    plt.show()\n",
    "    print('Accuracy of each class:\\n', cm.diag()/(cm.sum(1)+1e-6))\n",
    "    print('Recall of each class:\\n', cm.diag()/(cm.sum(0)+1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, optimizer, schedulr, device,nclasses):\n",
    "    \"\"\"\n",
    "     train and evaluate an classifier num_epochs times.\n",
    "    n and evaluate an classifier num_epochs times.\n",
    "    We use optimizer and cross entropy loss to train the model. \n",
    "    Args: \n",
    "        model: CNN network\n",
    "        num_epochs: the number of training epochs\n",
    "        optimizer: optimize the loss function    loss_func.to(device)\n",
    "    loss_func.to(device)\n",
    "        schedulr: scheduling learning rate\n",
    "\n",
    "    \"\"\"\n",
    "    # loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.to(device)\n",
    "    loss_func.to(device)\n",
    "    \n",
    "    # log train loss and test accuracy\n",
    "    losses = []\n",
    "    accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}: , lr = {}'.format(epoch + 1, num_epochs , optimizer.param_groups[0]['lr']))\n",
    "        # train step\n",
    "        loss = train(model, training_dataloader, loss_func, optimizer, device)\n",
    "        losses.append(loss)\n",
    "        schedulr.step()\n",
    "        \n",
    "        # evaluate step\n",
    "        accuracy = evaluate(model, test_dataloader, device,nclasses)\n",
    "        accs.append(accuracy)\n",
    "        \n",
    "    \n",
    "    # show curve\n",
    "    show_curve(losses, \"train loss\")\n",
    "    show_curve(accs, \"test accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Documents/dataset_skin40/SAN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "wd = os.getcwd()\n",
    "os.chdir(os.path.join(os.getcwd(),'../SAN'))\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelbest=torch.load('san19_pairwise/model/model_best.pth')\n",
    "# sdict = modelbest['state_dict']\n",
    "# for k,v in modelbest['state_dict'].items():\n",
    "#     print(type(k),k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_in.weight torch.Size([64, 3, 1, 1])\n",
      "bn_in.weight torch.Size([64])\n",
      "bn_in.bias torch.Size([64])\n",
      "bn_in.running_mean torch.Size([64])\n",
      "bn_in.running_var torch.Size([64])\n",
      "bn_in.num_batches_tracked torch.Size([])\n",
      "conv0.weight torch.Size([64, 64, 1, 1])\n",
      "bn0.weight torch.Size([64])\n",
      "bn0.bias torch.Size([64])\n",
      "bn0.running_mean torch.Size([64])\n",
      "bn0.running_var torch.Size([64])\n",
      "bn0.num_batches_tracked torch.Size([])\n",
      "layer0.0.bn1.weight torch.Size([64])\n",
      "layer0.0.bn1.bias torch.Size([64])\n",
      "layer0.0.bn1.running_mean torch.Size([64])\n",
      "layer0.0.bn1.running_var torch.Size([64])\n",
      "layer0.0.bn1.num_batches_tracked torch.Size([])\n",
      "layer0.0.sam.conv1.weight torch.Size([4, 64, 1, 1])\n",
      "layer0.0.sam.conv1.bias torch.Size([4])\n",
      "layer0.0.sam.conv2.weight torch.Size([4, 64, 1, 1])\n",
      "layer0.0.sam.conv2.bias torch.Size([4])\n",
      "layer0.0.sam.conv3.weight torch.Size([16, 64, 1, 1])\n",
      "layer0.0.sam.conv3.bias torch.Size([16])\n",
      "layer0.0.sam.conv_w.0.weight torch.Size([6])\n",
      "layer0.0.sam.conv_w.0.bias torch.Size([6])\n",
      "layer0.0.sam.conv_w.0.running_mean torch.Size([6])\n",
      "layer0.0.sam.conv_w.0.running_var torch.Size([6])\n",
      "layer0.0.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer0.0.sam.conv_w.2.weight torch.Size([4, 6, 1, 1])\n",
      "layer0.0.sam.conv_w.3.weight torch.Size([4])\n",
      "layer0.0.sam.conv_w.3.bias torch.Size([4])\n",
      "layer0.0.sam.conv_w.3.running_mean torch.Size([4])\n",
      "layer0.0.sam.conv_w.3.running_var torch.Size([4])\n",
      "layer0.0.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer0.0.sam.conv_w.5.weight torch.Size([2, 4, 1, 1])\n",
      "layer0.0.sam.conv_w.5.bias torch.Size([2])\n",
      "layer0.0.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer0.0.sam.conv_p.bias torch.Size([2])\n",
      "layer0.0.bn2.weight torch.Size([16])\n",
      "layer0.0.bn2.bias torch.Size([16])\n",
      "layer0.0.bn2.running_mean torch.Size([16])\n",
      "layer0.0.bn2.running_var torch.Size([16])\n",
      "layer0.0.bn2.num_batches_tracked torch.Size([])\n",
      "layer0.0.conv.weight torch.Size([64, 16, 1, 1])\n",
      "layer0.0.conv.bias torch.Size([64])\n",
      "layer0.1.bn1.weight torch.Size([64])\n",
      "layer0.1.bn1.bias torch.Size([64])\n",
      "layer0.1.bn1.running_mean torch.Size([64])\n",
      "layer0.1.bn1.running_var torch.Size([64])\n",
      "layer0.1.bn1.num_batches_tracked torch.Size([])\n",
      "layer0.1.sam.conv1.weight torch.Size([4, 64, 1, 1])\n",
      "layer0.1.sam.conv1.bias torch.Size([4])\n",
      "layer0.1.sam.conv2.weight torch.Size([4, 64, 1, 1])\n",
      "layer0.1.sam.conv2.bias torch.Size([4])\n",
      "layer0.1.sam.conv3.weight torch.Size([16, 64, 1, 1])\n",
      "layer0.1.sam.conv3.bias torch.Size([16])\n",
      "layer0.1.sam.conv_w.0.weight torch.Size([6])\n",
      "layer0.1.sam.conv_w.0.bias torch.Size([6])\n",
      "layer0.1.sam.conv_w.0.running_mean torch.Size([6])\n",
      "layer0.1.sam.conv_w.0.running_var torch.Size([6])\n",
      "layer0.1.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer0.1.sam.conv_w.2.weight torch.Size([4, 6, 1, 1])\n",
      "layer0.1.sam.conv_w.3.weight torch.Size([4])\n",
      "layer0.1.sam.conv_w.3.bias torch.Size([4])\n",
      "layer0.1.sam.conv_w.3.running_mean torch.Size([4])\n",
      "layer0.1.sam.conv_w.3.running_var torch.Size([4])\n",
      "layer0.1.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer0.1.sam.conv_w.5.weight torch.Size([2, 4, 1, 1])\n",
      "layer0.1.sam.conv_w.5.bias torch.Size([2])\n",
      "layer0.1.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer0.1.sam.conv_p.bias torch.Size([2])\n",
      "layer0.1.bn2.weight torch.Size([16])\n",
      "layer0.1.bn2.bias torch.Size([16])\n",
      "layer0.1.bn2.running_mean torch.Size([16])\n",
      "layer0.1.bn2.running_var torch.Size([16])\n",
      "layer0.1.bn2.num_batches_tracked torch.Size([])\n",
      "layer0.1.conv.weight torch.Size([64, 16, 1, 1])\n",
      "layer0.1.conv.bias torch.Size([64])\n",
      "layer0.2.bn1.weight torch.Size([64])\n",
      "layer0.2.bn1.bias torch.Size([64])\n",
      "layer0.2.bn1.running_mean torch.Size([64])\n",
      "layer0.2.bn1.running_var torch.Size([64])\n",
      "layer0.2.bn1.num_batches_tracked torch.Size([])\n",
      "layer0.2.sam.conv1.weight torch.Size([4, 64, 1, 1])\n",
      "layer0.2.sam.conv1.bias torch.Size([4])\n",
      "layer0.2.sam.conv2.weight torch.Size([4, 64, 1, 1])\n",
      "layer0.2.sam.conv2.bias torch.Size([4])\n",
      "layer0.2.sam.conv3.weight torch.Size([16, 64, 1, 1])\n",
      "layer0.2.sam.conv3.bias torch.Size([16])\n",
      "layer0.2.sam.conv_w.0.weight torch.Size([6])\n",
      "layer0.2.sam.conv_w.0.bias torch.Size([6])\n",
      "layer0.2.sam.conv_w.0.running_mean torch.Size([6])\n",
      "layer0.2.sam.conv_w.0.running_var torch.Size([6])\n",
      "layer0.2.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer0.2.sam.conv_w.2.weight torch.Size([4, 6, 1, 1])\n",
      "layer0.2.sam.conv_w.3.weight torch.Size([4])\n",
      "layer0.2.sam.conv_w.3.bias torch.Size([4])\n",
      "layer0.2.sam.conv_w.3.running_mean torch.Size([4])\n",
      "layer0.2.sam.conv_w.3.running_var torch.Size([4])\n",
      "layer0.2.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer0.2.sam.conv_w.5.weight torch.Size([2, 4, 1, 1])\n",
      "layer0.2.sam.conv_w.5.bias torch.Size([2])\n",
      "layer0.2.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer0.2.sam.conv_p.bias torch.Size([2])\n",
      "layer0.2.bn2.weight torch.Size([16])\n",
      "layer0.2.bn2.bias torch.Size([16])\n",
      "layer0.2.bn2.running_mean torch.Size([16])\n",
      "layer0.2.bn2.running_var torch.Size([16])\n",
      "layer0.2.bn2.num_batches_tracked torch.Size([])\n",
      "layer0.2.conv.weight torch.Size([64, 16, 1, 1])\n",
      "layer0.2.conv.bias torch.Size([64])\n",
      "conv1.weight torch.Size([256, 64, 1, 1])\n",
      "bn1.weight torch.Size([256])\n",
      "bn1.bias torch.Size([256])\n",
      "bn1.running_mean torch.Size([256])\n",
      "bn1.running_var torch.Size([256])\n",
      "bn1.num_batches_tracked torch.Size([])\n",
      "layer1.0.bn1.weight torch.Size([256])\n",
      "layer1.0.bn1.bias torch.Size([256])\n",
      "layer1.0.bn1.running_mean torch.Size([256])\n",
      "layer1.0.bn1.running_var torch.Size([256])\n",
      "layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "layer1.0.sam.conv1.weight torch.Size([16, 256, 1, 1])\n",
      "layer1.0.sam.conv1.bias torch.Size([16])\n",
      "layer1.0.sam.conv2.weight torch.Size([16, 256, 1, 1])\n",
      "layer1.0.sam.conv2.bias torch.Size([16])\n",
      "layer1.0.sam.conv3.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.0.sam.conv3.bias torch.Size([64])\n",
      "layer1.0.sam.conv_w.0.weight torch.Size([18])\n",
      "layer1.0.sam.conv_w.0.bias torch.Size([18])\n",
      "layer1.0.sam.conv_w.0.running_mean torch.Size([18])\n",
      "layer1.0.sam.conv_w.0.running_var torch.Size([18])\n",
      "layer1.0.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer1.0.sam.conv_w.2.weight torch.Size([16, 18, 1, 1])\n",
      "layer1.0.sam.conv_w.3.weight torch.Size([16])\n",
      "layer1.0.sam.conv_w.3.bias torch.Size([16])\n",
      "layer1.0.sam.conv_w.3.running_mean torch.Size([16])\n",
      "layer1.0.sam.conv_w.3.running_var torch.Size([16])\n",
      "layer1.0.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer1.0.sam.conv_w.5.weight torch.Size([8, 16, 1, 1])\n",
      "layer1.0.sam.conv_w.5.bias torch.Size([8])\n",
      "layer1.0.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer1.0.sam.conv_p.bias torch.Size([2])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.0.bn2.running_mean torch.Size([64])\n",
      "layer1.0.bn2.running_var torch.Size([64])\n",
      "layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "layer1.0.conv.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.conv.bias torch.Size([256])\n",
      "layer1.1.bn1.weight torch.Size([256])\n",
      "layer1.1.bn1.bias torch.Size([256])\n",
      "layer1.1.bn1.running_mean torch.Size([256])\n",
      "layer1.1.bn1.running_var torch.Size([256])\n",
      "layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "layer1.1.sam.conv1.weight torch.Size([16, 256, 1, 1])\n",
      "layer1.1.sam.conv1.bias torch.Size([16])\n",
      "layer1.1.sam.conv2.weight torch.Size([16, 256, 1, 1])\n",
      "layer1.1.sam.conv2.bias torch.Size([16])\n",
      "layer1.1.sam.conv3.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.1.sam.conv3.bias torch.Size([64])\n",
      "layer1.1.sam.conv_w.0.weight torch.Size([18])\n",
      "layer1.1.sam.conv_w.0.bias torch.Size([18])\n",
      "layer1.1.sam.conv_w.0.running_mean torch.Size([18])\n",
      "layer1.1.sam.conv_w.0.running_var torch.Size([18])\n",
      "layer1.1.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer1.1.sam.conv_w.2.weight torch.Size([16, 18, 1, 1])\n",
      "layer1.1.sam.conv_w.3.weight torch.Size([16])\n",
      "layer1.1.sam.conv_w.3.bias torch.Size([16])\n",
      "layer1.1.sam.conv_w.3.running_mean torch.Size([16])\n",
      "layer1.1.sam.conv_w.3.running_var torch.Size([16])\n",
      "layer1.1.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer1.1.sam.conv_w.5.weight torch.Size([8, 16, 1, 1])\n",
      "layer1.1.sam.conv_w.5.bias torch.Size([8])\n",
      "layer1.1.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer1.1.sam.conv_p.bias torch.Size([2])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer1.1.bn2.running_mean torch.Size([64])\n",
      "layer1.1.bn2.running_var torch.Size([64])\n",
      "layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "layer1.1.conv.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.1.conv.bias torch.Size([256])\n",
      "layer1.2.bn1.weight torch.Size([256])\n",
      "layer1.2.bn1.bias torch.Size([256])\n",
      "layer1.2.bn1.running_mean torch.Size([256])\n",
      "layer1.2.bn1.running_var torch.Size([256])\n",
      "layer1.2.bn1.num_batches_tracked torch.Size([])\n",
      "layer1.2.sam.conv1.weight torch.Size([16, 256, 1, 1])\n",
      "layer1.2.sam.conv1.bias torch.Size([16])\n",
      "layer1.2.sam.conv2.weight torch.Size([16, 256, 1, 1])\n",
      "layer1.2.sam.conv2.bias torch.Size([16])\n",
      "layer1.2.sam.conv3.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.2.sam.conv3.bias torch.Size([64])\n",
      "layer1.2.sam.conv_w.0.weight torch.Size([18])\n",
      "layer1.2.sam.conv_w.0.bias torch.Size([18])\n",
      "layer1.2.sam.conv_w.0.running_mean torch.Size([18])\n",
      "layer1.2.sam.conv_w.0.running_var torch.Size([18])\n",
      "layer1.2.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer1.2.sam.conv_w.2.weight torch.Size([16, 18, 1, 1])\n",
      "layer1.2.sam.conv_w.3.weight torch.Size([16])\n",
      "layer1.2.sam.conv_w.3.bias torch.Size([16])\n",
      "layer1.2.sam.conv_w.3.running_mean torch.Size([16])\n",
      "layer1.2.sam.conv_w.3.running_var torch.Size([16])\n",
      "layer1.2.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer1.2.sam.conv_w.5.weight torch.Size([8, 16, 1, 1])\n",
      "layer1.2.sam.conv_w.5.bias torch.Size([8])\n",
      "layer1.2.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer1.2.sam.conv_p.bias torch.Size([2])\n",
      "layer1.2.bn2.weight torch.Size([64])\n",
      "layer1.2.bn2.bias torch.Size([64])\n",
      "layer1.2.bn2.running_mean torch.Size([64])\n",
      "layer1.2.bn2.running_var torch.Size([64])\n",
      "layer1.2.bn2.num_batches_tracked torch.Size([])\n",
      "layer1.2.conv.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.2.conv.bias torch.Size([256])\n",
      "conv2.weight torch.Size([512, 256, 1, 1])\n",
      "bn2.weight torch.Size([512])\n",
      "bn2.bias torch.Size([512])\n",
      "bn2.running_mean torch.Size([512])\n",
      "bn2.running_var torch.Size([512])\n",
      "bn2.num_batches_tracked torch.Size([])\n",
      "layer2.0.bn1.weight torch.Size([512])\n",
      "layer2.0.bn1.bias torch.Size([512])\n",
      "layer2.0.bn1.running_mean torch.Size([512])\n",
      "layer2.0.bn1.running_var torch.Size([512])\n",
      "layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "layer2.0.sam.conv1.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.0.sam.conv1.bias torch.Size([32])\n",
      "layer2.0.sam.conv2.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.0.sam.conv2.bias torch.Size([32])\n",
      "layer2.0.sam.conv3.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.0.sam.conv3.bias torch.Size([128])\n",
      "layer2.0.sam.conv_w.0.weight torch.Size([34])\n",
      "layer2.0.sam.conv_w.0.bias torch.Size([34])\n",
      "layer2.0.sam.conv_w.0.running_mean torch.Size([34])\n",
      "layer2.0.sam.conv_w.0.running_var torch.Size([34])\n",
      "layer2.0.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer2.0.sam.conv_w.2.weight torch.Size([32, 34, 1, 1])\n",
      "layer2.0.sam.conv_w.3.weight torch.Size([32])\n",
      "layer2.0.sam.conv_w.3.bias torch.Size([32])\n",
      "layer2.0.sam.conv_w.3.running_mean torch.Size([32])\n",
      "layer2.0.sam.conv_w.3.running_var torch.Size([32])\n",
      "layer2.0.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer2.0.sam.conv_w.5.weight torch.Size([16, 32, 1, 1])\n",
      "layer2.0.sam.conv_w.5.bias torch.Size([16])\n",
      "layer2.0.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer2.0.sam.conv_p.bias torch.Size([2])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.bn2.running_mean torch.Size([128])\n",
      "layer2.0.bn2.running_var torch.Size([128])\n",
      "layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "layer2.0.conv.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.0.conv.bias torch.Size([512])\n",
      "layer2.1.bn1.weight torch.Size([512])\n",
      "layer2.1.bn1.bias torch.Size([512])\n",
      "layer2.1.bn1.running_mean torch.Size([512])\n",
      "layer2.1.bn1.running_var torch.Size([512])\n",
      "layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "layer2.1.sam.conv1.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.1.sam.conv1.bias torch.Size([32])\n",
      "layer2.1.sam.conv2.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.1.sam.conv2.bias torch.Size([32])\n",
      "layer2.1.sam.conv3.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.1.sam.conv3.bias torch.Size([128])\n",
      "layer2.1.sam.conv_w.0.weight torch.Size([34])\n",
      "layer2.1.sam.conv_w.0.bias torch.Size([34])\n",
      "layer2.1.sam.conv_w.0.running_mean torch.Size([34])\n",
      "layer2.1.sam.conv_w.0.running_var torch.Size([34])\n",
      "layer2.1.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer2.1.sam.conv_w.2.weight torch.Size([32, 34, 1, 1])\n",
      "layer2.1.sam.conv_w.3.weight torch.Size([32])\n",
      "layer2.1.sam.conv_w.3.bias torch.Size([32])\n",
      "layer2.1.sam.conv_w.3.running_mean torch.Size([32])\n",
      "layer2.1.sam.conv_w.3.running_var torch.Size([32])\n",
      "layer2.1.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer2.1.sam.conv_w.5.weight torch.Size([16, 32, 1, 1])\n",
      "layer2.1.sam.conv_w.5.bias torch.Size([16])\n",
      "layer2.1.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer2.1.sam.conv_p.bias torch.Size([2])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer2.1.bn2.running_mean torch.Size([128])\n",
      "layer2.1.bn2.running_var torch.Size([128])\n",
      "layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "layer2.1.conv.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.1.conv.bias torch.Size([512])\n",
      "layer2.2.bn1.weight torch.Size([512])\n",
      "layer2.2.bn1.bias torch.Size([512])\n",
      "layer2.2.bn1.running_mean torch.Size([512])\n",
      "layer2.2.bn1.running_var torch.Size([512])\n",
      "layer2.2.bn1.num_batches_tracked torch.Size([])\n",
      "layer2.2.sam.conv1.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.2.sam.conv1.bias torch.Size([32])\n",
      "layer2.2.sam.conv2.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.2.sam.conv2.bias torch.Size([32])\n",
      "layer2.2.sam.conv3.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.2.sam.conv3.bias torch.Size([128])\n",
      "layer2.2.sam.conv_w.0.weight torch.Size([34])\n",
      "layer2.2.sam.conv_w.0.bias torch.Size([34])\n",
      "layer2.2.sam.conv_w.0.running_mean torch.Size([34])\n",
      "layer2.2.sam.conv_w.0.running_var torch.Size([34])\n",
      "layer2.2.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer2.2.sam.conv_w.2.weight torch.Size([32, 34, 1, 1])\n",
      "layer2.2.sam.conv_w.3.weight torch.Size([32])\n",
      "layer2.2.sam.conv_w.3.bias torch.Size([32])\n",
      "layer2.2.sam.conv_w.3.running_mean torch.Size([32])\n",
      "layer2.2.sam.conv_w.3.running_var torch.Size([32])\n",
      "layer2.2.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer2.2.sam.conv_w.5.weight torch.Size([16, 32, 1, 1])\n",
      "layer2.2.sam.conv_w.5.bias torch.Size([16])\n",
      "layer2.2.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer2.2.sam.conv_p.bias torch.Size([2])\n",
      "layer2.2.bn2.weight torch.Size([128])\n",
      "layer2.2.bn2.bias torch.Size([128])\n",
      "layer2.2.bn2.running_mean torch.Size([128])\n",
      "layer2.2.bn2.running_var torch.Size([128])\n",
      "layer2.2.bn2.num_batches_tracked torch.Size([])\n",
      "layer2.2.conv.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.2.conv.bias torch.Size([512])\n",
      "layer2.3.bn1.weight torch.Size([512])\n",
      "layer2.3.bn1.bias torch.Size([512])\n",
      "layer2.3.bn1.running_mean torch.Size([512])\n",
      "layer2.3.bn1.running_var torch.Size([512])\n",
      "layer2.3.bn1.num_batches_tracked torch.Size([])\n",
      "layer2.3.sam.conv1.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.3.sam.conv1.bias torch.Size([32])\n",
      "layer2.3.sam.conv2.weight torch.Size([32, 512, 1, 1])\n",
      "layer2.3.sam.conv2.bias torch.Size([32])\n",
      "layer2.3.sam.conv3.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.3.sam.conv3.bias torch.Size([128])\n",
      "layer2.3.sam.conv_w.0.weight torch.Size([34])\n",
      "layer2.3.sam.conv_w.0.bias torch.Size([34])\n",
      "layer2.3.sam.conv_w.0.running_mean torch.Size([34])\n",
      "layer2.3.sam.conv_w.0.running_var torch.Size([34])\n",
      "layer2.3.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer2.3.sam.conv_w.2.weight torch.Size([32, 34, 1, 1])\n",
      "layer2.3.sam.conv_w.3.weight torch.Size([32])\n",
      "layer2.3.sam.conv_w.3.bias torch.Size([32])\n",
      "layer2.3.sam.conv_w.3.running_mean torch.Size([32])\n",
      "layer2.3.sam.conv_w.3.running_var torch.Size([32])\n",
      "layer2.3.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer2.3.sam.conv_w.5.weight torch.Size([16, 32, 1, 1])\n",
      "layer2.3.sam.conv_w.5.bias torch.Size([16])\n",
      "layer2.3.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer2.3.sam.conv_p.bias torch.Size([2])\n",
      "layer2.3.bn2.weight torch.Size([128])\n",
      "layer2.3.bn2.bias torch.Size([128])\n",
      "layer2.3.bn2.running_mean torch.Size([128])\n",
      "layer2.3.bn2.running_var torch.Size([128])\n",
      "layer2.3.bn2.num_batches_tracked torch.Size([])\n",
      "layer2.3.conv.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.3.conv.bias torch.Size([512])\n",
      "conv3.weight torch.Size([1024, 512, 1, 1])\n",
      "bn3.weight torch.Size([1024])\n",
      "bn3.bias torch.Size([1024])\n",
      "bn3.running_mean torch.Size([1024])\n",
      "bn3.running_var torch.Size([1024])\n",
      "bn3.num_batches_tracked torch.Size([])\n",
      "layer3.0.bn1.weight torch.Size([1024])\n",
      "layer3.0.bn1.bias torch.Size([1024])\n",
      "layer3.0.bn1.running_mean torch.Size([1024])\n",
      "layer3.0.bn1.running_var torch.Size([1024])\n",
      "layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "layer3.0.sam.conv1.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.0.sam.conv1.bias torch.Size([64])\n",
      "layer3.0.sam.conv2.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.0.sam.conv2.bias torch.Size([64])\n",
      "layer3.0.sam.conv3.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.0.sam.conv3.bias torch.Size([256])\n",
      "layer3.0.sam.conv_w.0.weight torch.Size([66])\n",
      "layer3.0.sam.conv_w.0.bias torch.Size([66])\n",
      "layer3.0.sam.conv_w.0.running_mean torch.Size([66])\n",
      "layer3.0.sam.conv_w.0.running_var torch.Size([66])\n",
      "layer3.0.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer3.0.sam.conv_w.2.weight torch.Size([64, 66, 1, 1])\n",
      "layer3.0.sam.conv_w.3.weight torch.Size([64])\n",
      "layer3.0.sam.conv_w.3.bias torch.Size([64])\n",
      "layer3.0.sam.conv_w.3.running_mean torch.Size([64])\n",
      "layer3.0.sam.conv_w.3.running_var torch.Size([64])\n",
      "layer3.0.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer3.0.sam.conv_w.5.weight torch.Size([32, 64, 1, 1])\n",
      "layer3.0.sam.conv_w.5.bias torch.Size([32])\n",
      "layer3.0.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer3.0.sam.conv_p.bias torch.Size([2])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.bn2.running_mean torch.Size([256])\n",
      "layer3.0.bn2.running_var torch.Size([256])\n",
      "layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "layer3.0.conv.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.conv.bias torch.Size([1024])\n",
      "layer3.1.bn1.weight torch.Size([1024])\n",
      "layer3.1.bn1.bias torch.Size([1024])\n",
      "layer3.1.bn1.running_mean torch.Size([1024])\n",
      "layer3.1.bn1.running_var torch.Size([1024])\n",
      "layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "layer3.1.sam.conv1.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.1.sam.conv1.bias torch.Size([64])\n",
      "layer3.1.sam.conv2.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.1.sam.conv2.bias torch.Size([64])\n",
      "layer3.1.sam.conv3.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.sam.conv3.bias torch.Size([256])\n",
      "layer3.1.sam.conv_w.0.weight torch.Size([66])\n",
      "layer3.1.sam.conv_w.0.bias torch.Size([66])\n",
      "layer3.1.sam.conv_w.0.running_mean torch.Size([66])\n",
      "layer3.1.sam.conv_w.0.running_var torch.Size([66])\n",
      "layer3.1.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer3.1.sam.conv_w.2.weight torch.Size([64, 66, 1, 1])\n",
      "layer3.1.sam.conv_w.3.weight torch.Size([64])\n",
      "layer3.1.sam.conv_w.3.bias torch.Size([64])\n",
      "layer3.1.sam.conv_w.3.running_mean torch.Size([64])\n",
      "layer3.1.sam.conv_w.3.running_var torch.Size([64])\n",
      "layer3.1.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer3.1.sam.conv_w.5.weight torch.Size([32, 64, 1, 1])\n",
      "layer3.1.sam.conv_w.5.bias torch.Size([32])\n",
      "layer3.1.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer3.1.sam.conv_p.bias torch.Size([2])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer3.1.bn2.running_mean torch.Size([256])\n",
      "layer3.1.bn2.running_var torch.Size([256])\n",
      "layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "layer3.1.conv.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.conv.bias torch.Size([1024])\n",
      "layer3.2.bn1.weight torch.Size([1024])\n",
      "layer3.2.bn1.bias torch.Size([1024])\n",
      "layer3.2.bn1.running_mean torch.Size([1024])\n",
      "layer3.2.bn1.running_var torch.Size([1024])\n",
      "layer3.2.bn1.num_batches_tracked torch.Size([])\n",
      "layer3.2.sam.conv1.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.2.sam.conv1.bias torch.Size([64])\n",
      "layer3.2.sam.conv2.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.2.sam.conv2.bias torch.Size([64])\n",
      "layer3.2.sam.conv3.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.sam.conv3.bias torch.Size([256])\n",
      "layer3.2.sam.conv_w.0.weight torch.Size([66])\n",
      "layer3.2.sam.conv_w.0.bias torch.Size([66])\n",
      "layer3.2.sam.conv_w.0.running_mean torch.Size([66])\n",
      "layer3.2.sam.conv_w.0.running_var torch.Size([66])\n",
      "layer3.2.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer3.2.sam.conv_w.2.weight torch.Size([64, 66, 1, 1])\n",
      "layer3.2.sam.conv_w.3.weight torch.Size([64])\n",
      "layer3.2.sam.conv_w.3.bias torch.Size([64])\n",
      "layer3.2.sam.conv_w.3.running_mean torch.Size([64])\n",
      "layer3.2.sam.conv_w.3.running_var torch.Size([64])\n",
      "layer3.2.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer3.2.sam.conv_w.5.weight torch.Size([32, 64, 1, 1])\n",
      "layer3.2.sam.conv_w.5.bias torch.Size([32])\n",
      "layer3.2.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer3.2.sam.conv_p.bias torch.Size([2])\n",
      "layer3.2.bn2.weight torch.Size([256])\n",
      "layer3.2.bn2.bias torch.Size([256])\n",
      "layer3.2.bn2.running_mean torch.Size([256])\n",
      "layer3.2.bn2.running_var torch.Size([256])\n",
      "layer3.2.bn2.num_batches_tracked torch.Size([])\n",
      "layer3.2.conv.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.conv.bias torch.Size([1024])\n",
      "layer3.3.bn1.weight torch.Size([1024])\n",
      "layer3.3.bn1.bias torch.Size([1024])\n",
      "layer3.3.bn1.running_mean torch.Size([1024])\n",
      "layer3.3.bn1.running_var torch.Size([1024])\n",
      "layer3.3.bn1.num_batches_tracked torch.Size([])\n",
      "layer3.3.sam.conv1.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.3.sam.conv1.bias torch.Size([64])\n",
      "layer3.3.sam.conv2.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.3.sam.conv2.bias torch.Size([64])\n",
      "layer3.3.sam.conv3.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.sam.conv3.bias torch.Size([256])\n",
      "layer3.3.sam.conv_w.0.weight torch.Size([66])\n",
      "layer3.3.sam.conv_w.0.bias torch.Size([66])\n",
      "layer3.3.sam.conv_w.0.running_mean torch.Size([66])\n",
      "layer3.3.sam.conv_w.0.running_var torch.Size([66])\n",
      "layer3.3.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer3.3.sam.conv_w.2.weight torch.Size([64, 66, 1, 1])\n",
      "layer3.3.sam.conv_w.3.weight torch.Size([64])\n",
      "layer3.3.sam.conv_w.3.bias torch.Size([64])\n",
      "layer3.3.sam.conv_w.3.running_mean torch.Size([64])\n",
      "layer3.3.sam.conv_w.3.running_var torch.Size([64])\n",
      "layer3.3.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer3.3.sam.conv_w.5.weight torch.Size([32, 64, 1, 1])\n",
      "layer3.3.sam.conv_w.5.bias torch.Size([32])\n",
      "layer3.3.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer3.3.sam.conv_p.bias torch.Size([2])\n",
      "layer3.3.bn2.weight torch.Size([256])\n",
      "layer3.3.bn2.bias torch.Size([256])\n",
      "layer3.3.bn2.running_mean torch.Size([256])\n",
      "layer3.3.bn2.running_var torch.Size([256])\n",
      "layer3.3.bn2.num_batches_tracked torch.Size([])\n",
      "layer3.3.conv.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.conv.bias torch.Size([1024])\n",
      "layer3.4.bn1.weight torch.Size([1024])\n",
      "layer3.4.bn1.bias torch.Size([1024])\n",
      "layer3.4.bn1.running_mean torch.Size([1024])\n",
      "layer3.4.bn1.running_var torch.Size([1024])\n",
      "layer3.4.bn1.num_batches_tracked torch.Size([])\n",
      "layer3.4.sam.conv1.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.4.sam.conv1.bias torch.Size([64])\n",
      "layer3.4.sam.conv2.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.4.sam.conv2.bias torch.Size([64])\n",
      "layer3.4.sam.conv3.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.sam.conv3.bias torch.Size([256])\n",
      "layer3.4.sam.conv_w.0.weight torch.Size([66])\n",
      "layer3.4.sam.conv_w.0.bias torch.Size([66])\n",
      "layer3.4.sam.conv_w.0.running_mean torch.Size([66])\n",
      "layer3.4.sam.conv_w.0.running_var torch.Size([66])\n",
      "layer3.4.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer3.4.sam.conv_w.2.weight torch.Size([64, 66, 1, 1])\n",
      "layer3.4.sam.conv_w.3.weight torch.Size([64])\n",
      "layer3.4.sam.conv_w.3.bias torch.Size([64])\n",
      "layer3.4.sam.conv_w.3.running_mean torch.Size([64])\n",
      "layer3.4.sam.conv_w.3.running_var torch.Size([64])\n",
      "layer3.4.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer3.4.sam.conv_w.5.weight torch.Size([32, 64, 1, 1])\n",
      "layer3.4.sam.conv_w.5.bias torch.Size([32])\n",
      "layer3.4.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer3.4.sam.conv_p.bias torch.Size([2])\n",
      "layer3.4.bn2.weight torch.Size([256])\n",
      "layer3.4.bn2.bias torch.Size([256])\n",
      "layer3.4.bn2.running_mean torch.Size([256])\n",
      "layer3.4.bn2.running_var torch.Size([256])\n",
      "layer3.4.bn2.num_batches_tracked torch.Size([])\n",
      "layer3.4.conv.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.conv.bias torch.Size([1024])\n",
      "layer3.5.bn1.weight torch.Size([1024])\n",
      "layer3.5.bn1.bias torch.Size([1024])\n",
      "layer3.5.bn1.running_mean torch.Size([1024])\n",
      "layer3.5.bn1.running_var torch.Size([1024])\n",
      "layer3.5.bn1.num_batches_tracked torch.Size([])\n",
      "layer3.5.sam.conv1.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.5.sam.conv1.bias torch.Size([64])\n",
      "layer3.5.sam.conv2.weight torch.Size([64, 1024, 1, 1])\n",
      "layer3.5.sam.conv2.bias torch.Size([64])\n",
      "layer3.5.sam.conv3.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.sam.conv3.bias torch.Size([256])\n",
      "layer3.5.sam.conv_w.0.weight torch.Size([66])\n",
      "layer3.5.sam.conv_w.0.bias torch.Size([66])\n",
      "layer3.5.sam.conv_w.0.running_mean torch.Size([66])\n",
      "layer3.5.sam.conv_w.0.running_var torch.Size([66])\n",
      "layer3.5.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer3.5.sam.conv_w.2.weight torch.Size([64, 66, 1, 1])\n",
      "layer3.5.sam.conv_w.3.weight torch.Size([64])\n",
      "layer3.5.sam.conv_w.3.bias torch.Size([64])\n",
      "layer3.5.sam.conv_w.3.running_mean torch.Size([64])\n",
      "layer3.5.sam.conv_w.3.running_var torch.Size([64])\n",
      "layer3.5.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer3.5.sam.conv_w.5.weight torch.Size([32, 64, 1, 1])\n",
      "layer3.5.sam.conv_w.5.bias torch.Size([32])\n",
      "layer3.5.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer3.5.sam.conv_p.bias torch.Size([2])\n",
      "layer3.5.bn2.weight torch.Size([256])\n",
      "layer3.5.bn2.bias torch.Size([256])\n",
      "layer3.5.bn2.running_mean torch.Size([256])\n",
      "layer3.5.bn2.running_var torch.Size([256])\n",
      "layer3.5.bn2.num_batches_tracked torch.Size([])\n",
      "layer3.5.conv.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.conv.bias torch.Size([1024])\n",
      "conv4.weight torch.Size([2048, 1024, 1, 1])\n",
      "bn4.weight torch.Size([2048])\n",
      "bn4.bias torch.Size([2048])\n",
      "bn4.running_mean torch.Size([2048])\n",
      "bn4.running_var torch.Size([2048])\n",
      "bn4.num_batches_tracked torch.Size([])\n",
      "layer4.0.bn1.weight torch.Size([2048])\n",
      "layer4.0.bn1.bias torch.Size([2048])\n",
      "layer4.0.bn1.running_mean torch.Size([2048])\n",
      "layer4.0.bn1.running_var torch.Size([2048])\n",
      "layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "layer4.0.sam.conv1.weight torch.Size([128, 2048, 1, 1])\n",
      "layer4.0.sam.conv1.bias torch.Size([128])\n",
      "layer4.0.sam.conv2.weight torch.Size([128, 2048, 1, 1])\n",
      "layer4.0.sam.conv2.bias torch.Size([128])\n",
      "layer4.0.sam.conv3.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.0.sam.conv3.bias torch.Size([512])\n",
      "layer4.0.sam.conv_w.0.weight torch.Size([130])\n",
      "layer4.0.sam.conv_w.0.bias torch.Size([130])\n",
      "layer4.0.sam.conv_w.0.running_mean torch.Size([130])\n",
      "layer4.0.sam.conv_w.0.running_var torch.Size([130])\n",
      "layer4.0.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer4.0.sam.conv_w.2.weight torch.Size([128, 130, 1, 1])\n",
      "layer4.0.sam.conv_w.3.weight torch.Size([128])\n",
      "layer4.0.sam.conv_w.3.bias torch.Size([128])\n",
      "layer4.0.sam.conv_w.3.running_mean torch.Size([128])\n",
      "layer4.0.sam.conv_w.3.running_var torch.Size([128])\n",
      "layer4.0.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer4.0.sam.conv_w.5.weight torch.Size([64, 128, 1, 1])\n",
      "layer4.0.sam.conv_w.5.bias torch.Size([64])\n",
      "layer4.0.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer4.0.sam.conv_p.bias torch.Size([2])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.bn2.running_mean torch.Size([512])\n",
      "layer4.0.bn2.running_var torch.Size([512])\n",
      "layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "layer4.0.conv.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.conv.bias torch.Size([2048])\n",
      "layer4.1.bn1.weight torch.Size([2048])\n",
      "layer4.1.bn1.bias torch.Size([2048])\n",
      "layer4.1.bn1.running_mean torch.Size([2048])\n",
      "layer4.1.bn1.running_var torch.Size([2048])\n",
      "layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "layer4.1.sam.conv1.weight torch.Size([128, 2048, 1, 1])\n",
      "layer4.1.sam.conv1.bias torch.Size([128])\n",
      "layer4.1.sam.conv2.weight torch.Size([128, 2048, 1, 1])\n",
      "layer4.1.sam.conv2.bias torch.Size([128])\n",
      "layer4.1.sam.conv3.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.sam.conv3.bias torch.Size([512])\n",
      "layer4.1.sam.conv_w.0.weight torch.Size([130])\n",
      "layer4.1.sam.conv_w.0.bias torch.Size([130])\n",
      "layer4.1.sam.conv_w.0.running_mean torch.Size([130])\n",
      "layer4.1.sam.conv_w.0.running_var torch.Size([130])\n",
      "layer4.1.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer4.1.sam.conv_w.2.weight torch.Size([128, 130, 1, 1])\n",
      "layer4.1.sam.conv_w.3.weight torch.Size([128])\n",
      "layer4.1.sam.conv_w.3.bias torch.Size([128])\n",
      "layer4.1.sam.conv_w.3.running_mean torch.Size([128])\n",
      "layer4.1.sam.conv_w.3.running_var torch.Size([128])\n",
      "layer4.1.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer4.1.sam.conv_w.5.weight torch.Size([64, 128, 1, 1])\n",
      "layer4.1.sam.conv_w.5.bias torch.Size([64])\n",
      "layer4.1.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer4.1.sam.conv_p.bias torch.Size([2])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "layer4.1.bn2.running_mean torch.Size([512])\n",
      "layer4.1.bn2.running_var torch.Size([512])\n",
      "layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "layer4.1.conv.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.conv.bias torch.Size([2048])\n",
      "layer4.2.bn1.weight torch.Size([2048])\n",
      "layer4.2.bn1.bias torch.Size([2048])\n",
      "layer4.2.bn1.running_mean torch.Size([2048])\n",
      "layer4.2.bn1.running_var torch.Size([2048])\n",
      "layer4.2.bn1.num_batches_tracked torch.Size([])\n",
      "layer4.2.sam.conv1.weight torch.Size([128, 2048, 1, 1])\n",
      "layer4.2.sam.conv1.bias torch.Size([128])\n",
      "layer4.2.sam.conv2.weight torch.Size([128, 2048, 1, 1])\n",
      "layer4.2.sam.conv2.bias torch.Size([128])\n",
      "layer4.2.sam.conv3.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.sam.conv3.bias torch.Size([512])\n",
      "layer4.2.sam.conv_w.0.weight torch.Size([130])\n",
      "layer4.2.sam.conv_w.0.bias torch.Size([130])\n",
      "layer4.2.sam.conv_w.0.running_mean torch.Size([130])\n",
      "layer4.2.sam.conv_w.0.running_var torch.Size([130])\n",
      "layer4.2.sam.conv_w.0.num_batches_tracked torch.Size([])\n",
      "layer4.2.sam.conv_w.2.weight torch.Size([128, 130, 1, 1])\n",
      "layer4.2.sam.conv_w.3.weight torch.Size([128])\n",
      "layer4.2.sam.conv_w.3.bias torch.Size([128])\n",
      "layer4.2.sam.conv_w.3.running_mean torch.Size([128])\n",
      "layer4.2.sam.conv_w.3.running_var torch.Size([128])\n",
      "layer4.2.sam.conv_w.3.num_batches_tracked torch.Size([])\n",
      "layer4.2.sam.conv_w.5.weight torch.Size([64, 128, 1, 1])\n",
      "layer4.2.sam.conv_w.5.bias torch.Size([64])\n",
      "layer4.2.sam.conv_p.weight torch.Size([2, 2, 1, 1])\n",
      "layer4.2.sam.conv_p.bias torch.Size([2])\n",
      "layer4.2.bn2.weight torch.Size([512])\n",
      "layer4.2.bn2.bias torch.Size([512])\n",
      "layer4.2.bn2.running_mean torch.Size([512])\n",
      "layer4.2.bn2.running_var torch.Size([512])\n",
      "layer4.2.bn2.num_batches_tracked torch.Size([])\n",
      "layer4.2.conv.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.conv.bias torch.Size([2048])\n",
      "fc.0.weight torch.Size([4096, 2048])\n",
      "fc.0.bias torch.Size([4096])\n",
      "fc.3.weight torch.Size([10, 4096])\n",
      "fc.3.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "from model import san\n",
    "net = san(sa_type=0, layers=(3, 3, 4, 6, 3), kernels=[3, 7, 7, 7, 7], num_classes=1000)\n",
    "net.load_state_dict({k[7:]:v for k,v in modelbest['state_dict'].items()})\n",
    "# net = modelbest\n",
    "net.fc = torch.nn.Sequential(nn.Linear(2048, 4096),\n",
    "                             nn.Sigmoid(),\n",
    "                             nn.Dropout(p=0.6),\n",
    "                             nn.Linear(4096, 10)\n",
    "                            )\n",
    "for k,v in net.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Documents/dataset_skin40/SYSUDeepLearningSkin\n"
     ]
    }
   ],
   "source": [
    "os.chdir(wd)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False conv_in.weight\n",
      "False bn_in.weight\n",
      "False bn_in.bias\n",
      "False conv0.weight\n",
      "False bn0.weight\n",
      "False bn0.bias\n",
      "False layer0.0.bn1.weight\n",
      "False layer0.0.bn1.bias\n",
      "False layer0.0.sam.conv1.weight\n",
      "False layer0.0.sam.conv1.bias\n",
      "False layer0.0.sam.conv2.weight\n",
      "False layer0.0.sam.conv2.bias\n",
      "False layer0.0.sam.conv3.weight\n",
      "False layer0.0.sam.conv3.bias\n",
      "False layer0.0.sam.conv_w.0.weight\n",
      "False layer0.0.sam.conv_w.0.bias\n",
      "False layer0.0.sam.conv_w.2.weight\n",
      "False layer0.0.sam.conv_w.3.weight\n",
      "False layer0.0.sam.conv_w.3.bias\n",
      "False layer0.0.sam.conv_w.5.weight\n",
      "False layer0.0.sam.conv_w.5.bias\n",
      "False layer0.0.sam.conv_p.weight\n",
      "False layer0.0.sam.conv_p.bias\n",
      "False layer0.0.bn2.weight\n",
      "False layer0.0.bn2.bias\n",
      "False layer0.0.conv.weight\n",
      "False layer0.0.conv.bias\n",
      "False layer0.1.bn1.weight\n",
      "False layer0.1.bn1.bias\n",
      "False layer0.1.sam.conv1.weight\n",
      "False layer0.1.sam.conv1.bias\n",
      "False layer0.1.sam.conv2.weight\n",
      "False layer0.1.sam.conv2.bias\n",
      "False layer0.1.sam.conv3.weight\n",
      "False layer0.1.sam.conv3.bias\n",
      "False layer0.1.sam.conv_w.0.weight\n",
      "False layer0.1.sam.conv_w.0.bias\n",
      "False layer0.1.sam.conv_w.2.weight\n",
      "False layer0.1.sam.conv_w.3.weight\n",
      "False layer0.1.sam.conv_w.3.bias\n",
      "False layer0.1.sam.conv_w.5.weight\n",
      "False layer0.1.sam.conv_w.5.bias\n",
      "False layer0.1.sam.conv_p.weight\n",
      "False layer0.1.sam.conv_p.bias\n",
      "False layer0.1.bn2.weight\n",
      "False layer0.1.bn2.bias\n",
      "False layer0.1.conv.weight\n",
      "False layer0.1.conv.bias\n",
      "False layer0.2.bn1.weight\n",
      "False layer0.2.bn1.bias\n",
      "False layer0.2.sam.conv1.weight\n",
      "False layer0.2.sam.conv1.bias\n",
      "False layer0.2.sam.conv2.weight\n",
      "False layer0.2.sam.conv2.bias\n",
      "False layer0.2.sam.conv3.weight\n",
      "False layer0.2.sam.conv3.bias\n",
      "False layer0.2.sam.conv_w.0.weight\n",
      "False layer0.2.sam.conv_w.0.bias\n",
      "False layer0.2.sam.conv_w.2.weight\n",
      "False layer0.2.sam.conv_w.3.weight\n",
      "False layer0.2.sam.conv_w.3.bias\n",
      "False layer0.2.sam.conv_w.5.weight\n",
      "False layer0.2.sam.conv_w.5.bias\n",
      "False layer0.2.sam.conv_p.weight\n",
      "False layer0.2.sam.conv_p.bias\n",
      "False layer0.2.bn2.weight\n",
      "False layer0.2.bn2.bias\n",
      "False layer0.2.conv.weight\n",
      "False layer0.2.conv.bias\n",
      "False conv1.weight\n",
      "False bn1.weight\n",
      "False bn1.bias\n",
      "False layer1.0.bn1.weight\n",
      "False layer1.0.bn1.bias\n",
      "False layer1.0.sam.conv1.weight\n",
      "False layer1.0.sam.conv1.bias\n",
      "False layer1.0.sam.conv2.weight\n",
      "False layer1.0.sam.conv2.bias\n",
      "False layer1.0.sam.conv3.weight\n",
      "False layer1.0.sam.conv3.bias\n",
      "False layer1.0.sam.conv_w.0.weight\n",
      "False layer1.0.sam.conv_w.0.bias\n",
      "False layer1.0.sam.conv_w.2.weight\n",
      "False layer1.0.sam.conv_w.3.weight\n",
      "False layer1.0.sam.conv_w.3.bias\n",
      "False layer1.0.sam.conv_w.5.weight\n",
      "False layer1.0.sam.conv_w.5.bias\n",
      "False layer1.0.sam.conv_p.weight\n",
      "False layer1.0.sam.conv_p.bias\n",
      "False layer1.0.bn2.weight\n",
      "False layer1.0.bn2.bias\n",
      "False layer1.0.conv.weight\n",
      "False layer1.0.conv.bias\n",
      "False layer1.1.bn1.weight\n",
      "False layer1.1.bn1.bias\n",
      "False layer1.1.sam.conv1.weight\n",
      "False layer1.1.sam.conv1.bias\n",
      "False layer1.1.sam.conv2.weight\n",
      "False layer1.1.sam.conv2.bias\n",
      "False layer1.1.sam.conv3.weight\n",
      "False layer1.1.sam.conv3.bias\n",
      "False layer1.1.sam.conv_w.0.weight\n",
      "False layer1.1.sam.conv_w.0.bias\n",
      "False layer1.1.sam.conv_w.2.weight\n",
      "False layer1.1.sam.conv_w.3.weight\n",
      "False layer1.1.sam.conv_w.3.bias\n",
      "False layer1.1.sam.conv_w.5.weight\n",
      "False layer1.1.sam.conv_w.5.bias\n",
      "False layer1.1.sam.conv_p.weight\n",
      "False layer1.1.sam.conv_p.bias\n",
      "False layer1.1.bn2.weight\n",
      "False layer1.1.bn2.bias\n",
      "False layer1.1.conv.weight\n",
      "False layer1.1.conv.bias\n",
      "False layer1.2.bn1.weight\n",
      "False layer1.2.bn1.bias\n",
      "False layer1.2.sam.conv1.weight\n",
      "False layer1.2.sam.conv1.bias\n",
      "False layer1.2.sam.conv2.weight\n",
      "False layer1.2.sam.conv2.bias\n",
      "False layer1.2.sam.conv3.weight\n",
      "False layer1.2.sam.conv3.bias\n",
      "False layer1.2.sam.conv_w.0.weight\n",
      "False layer1.2.sam.conv_w.0.bias\n",
      "False layer1.2.sam.conv_w.2.weight\n",
      "False layer1.2.sam.conv_w.3.weight\n",
      "False layer1.2.sam.conv_w.3.bias\n",
      "False layer1.2.sam.conv_w.5.weight\n",
      "False layer1.2.sam.conv_w.5.bias\n",
      "False layer1.2.sam.conv_p.weight\n",
      "False layer1.2.sam.conv_p.bias\n",
      "False layer1.2.bn2.weight\n",
      "False layer1.2.bn2.bias\n",
      "False layer1.2.conv.weight\n",
      "False layer1.2.conv.bias\n",
      "False conv2.weight\n",
      "False bn2.weight\n",
      "False bn2.bias\n",
      "False layer2.0.bn1.weight\n",
      "False layer2.0.bn1.bias\n",
      "False layer2.0.sam.conv1.weight\n",
      "False layer2.0.sam.conv1.bias\n",
      "False layer2.0.sam.conv2.weight\n",
      "False layer2.0.sam.conv2.bias\n",
      "False layer2.0.sam.conv3.weight\n",
      "False layer2.0.sam.conv3.bias\n",
      "False layer2.0.sam.conv_w.0.weight\n",
      "False layer2.0.sam.conv_w.0.bias\n",
      "False layer2.0.sam.conv_w.2.weight\n",
      "False layer2.0.sam.conv_w.3.weight\n",
      "False layer2.0.sam.conv_w.3.bias\n",
      "False layer2.0.sam.conv_w.5.weight\n",
      "False layer2.0.sam.conv_w.5.bias\n",
      "False layer2.0.sam.conv_p.weight\n",
      "False layer2.0.sam.conv_p.bias\n",
      "False layer2.0.bn2.weight\n",
      "False layer2.0.bn2.bias\n",
      "False layer2.0.conv.weight\n",
      "False layer2.0.conv.bias\n",
      "False layer2.1.bn1.weight\n",
      "False layer2.1.bn1.bias\n",
      "False layer2.1.sam.conv1.weight\n",
      "False layer2.1.sam.conv1.bias\n",
      "False layer2.1.sam.conv2.weight\n",
      "False layer2.1.sam.conv2.bias\n",
      "False layer2.1.sam.conv3.weight\n",
      "False layer2.1.sam.conv3.bias\n",
      "False layer2.1.sam.conv_w.0.weight\n",
      "False layer2.1.sam.conv_w.0.bias\n",
      "False layer2.1.sam.conv_w.2.weight\n",
      "False layer2.1.sam.conv_w.3.weight\n",
      "False layer2.1.sam.conv_w.3.bias\n",
      "False layer2.1.sam.conv_w.5.weight\n",
      "False layer2.1.sam.conv_w.5.bias\n",
      "False layer2.1.sam.conv_p.weight\n",
      "False layer2.1.sam.conv_p.bias\n",
      "False layer2.1.bn2.weight\n",
      "False layer2.1.bn2.bias\n",
      "False layer2.1.conv.weight\n",
      "False layer2.1.conv.bias\n",
      "False layer2.2.bn1.weight\n",
      "False layer2.2.bn1.bias\n",
      "False layer2.2.sam.conv1.weight\n",
      "False layer2.2.sam.conv1.bias\n",
      "False layer2.2.sam.conv2.weight\n",
      "False layer2.2.sam.conv2.bias\n",
      "False layer2.2.sam.conv3.weight\n",
      "False layer2.2.sam.conv3.bias\n",
      "False layer2.2.sam.conv_w.0.weight\n",
      "False layer2.2.sam.conv_w.0.bias\n",
      "False layer2.2.sam.conv_w.2.weight\n",
      "False layer2.2.sam.conv_w.3.weight\n",
      "False layer2.2.sam.conv_w.3.bias\n",
      "False layer2.2.sam.conv_w.5.weight\n",
      "False layer2.2.sam.conv_w.5.bias\n",
      "False layer2.2.sam.conv_p.weight\n",
      "False layer2.2.sam.conv_p.bias\n",
      "False layer2.2.bn2.weight\n",
      "False layer2.2.bn2.bias\n",
      "False layer2.2.conv.weight\n",
      "False layer2.2.conv.bias\n",
      "False layer2.3.bn1.weight\n",
      "False layer2.3.bn1.bias\n",
      "False layer2.3.sam.conv1.weight\n",
      "False layer2.3.sam.conv1.bias\n",
      "False layer2.3.sam.conv2.weight\n",
      "False layer2.3.sam.conv2.bias\n",
      "False layer2.3.sam.conv3.weight\n",
      "False layer2.3.sam.conv3.bias\n",
      "False layer2.3.sam.conv_w.0.weight\n",
      "False layer2.3.sam.conv_w.0.bias\n",
      "False layer2.3.sam.conv_w.2.weight\n",
      "False layer2.3.sam.conv_w.3.weight\n",
      "False layer2.3.sam.conv_w.3.bias\n",
      "False layer2.3.sam.conv_w.5.weight\n",
      "False layer2.3.sam.conv_w.5.bias\n",
      "False layer2.3.sam.conv_p.weight\n",
      "False layer2.3.sam.conv_p.bias\n",
      "False layer2.3.bn2.weight\n",
      "False layer2.3.bn2.bias\n",
      "False layer2.3.conv.weight\n",
      "False layer2.3.conv.bias\n",
      "False conv3.weight\n",
      "False bn3.weight\n",
      "False bn3.bias\n",
      "False layer3.0.bn1.weight\n",
      "False layer3.0.bn1.bias\n",
      "False layer3.0.sam.conv1.weight\n",
      "False layer3.0.sam.conv1.bias\n",
      "False layer3.0.sam.conv2.weight\n",
      "False layer3.0.sam.conv2.bias\n",
      "False layer3.0.sam.conv3.weight\n",
      "False layer3.0.sam.conv3.bias\n",
      "False layer3.0.sam.conv_w.0.weight\n",
      "False layer3.0.sam.conv_w.0.bias\n",
      "False layer3.0.sam.conv_w.2.weight\n",
      "False layer3.0.sam.conv_w.3.weight\n",
      "False layer3.0.sam.conv_w.3.bias\n",
      "False layer3.0.sam.conv_w.5.weight\n",
      "False layer3.0.sam.conv_w.5.bias\n",
      "False layer3.0.sam.conv_p.weight\n",
      "False layer3.0.sam.conv_p.bias\n",
      "False layer3.0.bn2.weight\n",
      "False layer3.0.bn2.bias\n",
      "False layer3.0.conv.weight\n",
      "False layer3.0.conv.bias\n",
      "False layer3.1.bn1.weight\n",
      "False layer3.1.bn1.bias\n",
      "False layer3.1.sam.conv1.weight\n",
      "False layer3.1.sam.conv1.bias\n",
      "False layer3.1.sam.conv2.weight\n",
      "False layer3.1.sam.conv2.bias\n",
      "False layer3.1.sam.conv3.weight\n",
      "False layer3.1.sam.conv3.bias\n",
      "False layer3.1.sam.conv_w.0.weight\n",
      "False layer3.1.sam.conv_w.0.bias\n",
      "False layer3.1.sam.conv_w.2.weight\n",
      "False layer3.1.sam.conv_w.3.weight\n",
      "False layer3.1.sam.conv_w.3.bias\n",
      "False layer3.1.sam.conv_w.5.weight\n",
      "False layer3.1.sam.conv_w.5.bias\n",
      "False layer3.1.sam.conv_p.weight\n",
      "False layer3.1.sam.conv_p.bias\n",
      "False layer3.1.bn2.weight\n",
      "False layer3.1.bn2.bias\n",
      "False layer3.1.conv.weight\n",
      "False layer3.1.conv.bias\n",
      "False layer3.2.bn1.weight\n",
      "False layer3.2.bn1.bias\n",
      "False layer3.2.sam.conv1.weight\n",
      "False layer3.2.sam.conv1.bias\n",
      "False layer3.2.sam.conv2.weight\n",
      "False layer3.2.sam.conv2.bias\n",
      "False layer3.2.sam.conv3.weight\n",
      "False layer3.2.sam.conv3.bias\n",
      "False layer3.2.sam.conv_w.0.weight\n",
      "False layer3.2.sam.conv_w.0.bias\n",
      "False layer3.2.sam.conv_w.2.weight\n",
      "False layer3.2.sam.conv_w.3.weight\n",
      "False layer3.2.sam.conv_w.3.bias\n",
      "False layer3.2.sam.conv_w.5.weight\n",
      "False layer3.2.sam.conv_w.5.bias\n",
      "False layer3.2.sam.conv_p.weight\n",
      "False layer3.2.sam.conv_p.bias\n",
      "False layer3.2.bn2.weight\n",
      "False layer3.2.bn2.bias\n",
      "False layer3.2.conv.weight\n",
      "False layer3.2.conv.bias\n",
      "False layer3.3.bn1.weight\n",
      "False layer3.3.bn1.bias\n",
      "False layer3.3.sam.conv1.weight\n",
      "False layer3.3.sam.conv1.bias\n",
      "False layer3.3.sam.conv2.weight\n",
      "False layer3.3.sam.conv2.bias\n",
      "False layer3.3.sam.conv3.weight\n",
      "False layer3.3.sam.conv3.bias\n",
      "False layer3.3.sam.conv_w.0.weight\n",
      "False layer3.3.sam.conv_w.0.bias\n",
      "False layer3.3.sam.conv_w.2.weight\n",
      "False layer3.3.sam.conv_w.3.weight\n",
      "False layer3.3.sam.conv_w.3.bias\n",
      "False layer3.3.sam.conv_w.5.weight\n",
      "False layer3.3.sam.conv_w.5.bias\n",
      "False layer3.3.sam.conv_p.weight\n",
      "False layer3.3.sam.conv_p.bias\n",
      "False layer3.3.bn2.weight\n",
      "False layer3.3.bn2.bias\n",
      "False layer3.3.conv.weight\n",
      "False layer3.3.conv.bias\n",
      "False layer3.4.bn1.weight\n",
      "False layer3.4.bn1.bias\n",
      "False layer3.4.sam.conv1.weight\n",
      "False layer3.4.sam.conv1.bias\n",
      "False layer3.4.sam.conv2.weight\n",
      "False layer3.4.sam.conv2.bias\n",
      "False layer3.4.sam.conv3.weight\n",
      "False layer3.4.sam.conv3.bias\n",
      "False layer3.4.sam.conv_w.0.weight\n",
      "False layer3.4.sam.conv_w.0.bias\n",
      "False layer3.4.sam.conv_w.2.weight\n",
      "False layer3.4.sam.conv_w.3.weight\n",
      "False layer3.4.sam.conv_w.3.bias\n",
      "False layer3.4.sam.conv_w.5.weight\n",
      "False layer3.4.sam.conv_w.5.bias\n",
      "False layer3.4.sam.conv_p.weight\n",
      "False layer3.4.sam.conv_p.bias\n",
      "False layer3.4.bn2.weight\n",
      "False layer3.4.bn2.bias\n",
      "False layer3.4.conv.weight\n",
      "False layer3.4.conv.bias\n",
      "False layer3.5.bn1.weight\n",
      "False layer3.5.bn1.bias\n",
      "False layer3.5.sam.conv1.weight\n",
      "False layer3.5.sam.conv1.bias\n",
      "False layer3.5.sam.conv2.weight\n",
      "False layer3.5.sam.conv2.bias\n",
      "False layer3.5.sam.conv3.weight\n",
      "False layer3.5.sam.conv3.bias\n",
      "False layer3.5.sam.conv_w.0.weight\n",
      "False layer3.5.sam.conv_w.0.bias\n",
      "False layer3.5.sam.conv_w.2.weight\n",
      "False layer3.5.sam.conv_w.3.weight\n",
      "False layer3.5.sam.conv_w.3.bias\n",
      "False layer3.5.sam.conv_w.5.weight\n",
      "False layer3.5.sam.conv_w.5.bias\n",
      "False layer3.5.sam.conv_p.weight\n",
      "False layer3.5.sam.conv_p.bias\n",
      "False layer3.5.bn2.weight\n",
      "False layer3.5.bn2.bias\n",
      "False layer3.5.conv.weight\n",
      "False layer3.5.conv.bias\n",
      "False conv4.weight\n",
      "False bn4.weight\n",
      "False bn4.bias\n",
      "False layer4.0.bn1.weight\n",
      "False layer4.0.bn1.bias\n",
      "False layer4.0.sam.conv1.weight\n",
      "False layer4.0.sam.conv1.bias\n",
      "False layer4.0.sam.conv2.weight\n",
      "False layer4.0.sam.conv2.bias\n",
      "False layer4.0.sam.conv3.weight\n",
      "False layer4.0.sam.conv3.bias\n",
      "False layer4.0.sam.conv_w.0.weight\n",
      "False layer4.0.sam.conv_w.0.bias\n",
      "False layer4.0.sam.conv_w.2.weight\n",
      "False layer4.0.sam.conv_w.3.weight\n",
      "False layer4.0.sam.conv_w.3.bias\n",
      "False layer4.0.sam.conv_w.5.weight\n",
      "False layer4.0.sam.conv_w.5.bias\n",
      "False layer4.0.sam.conv_p.weight\n",
      "False layer4.0.sam.conv_p.bias\n",
      "False layer4.0.bn2.weight\n",
      "False layer4.0.bn2.bias\n",
      "False layer4.0.conv.weight\n",
      "False layer4.0.conv.bias\n",
      "False layer4.1.bn1.weight\n",
      "False layer4.1.bn1.bias\n",
      "False layer4.1.sam.conv1.weight\n",
      "False layer4.1.sam.conv1.bias\n",
      "False layer4.1.sam.conv2.weight\n",
      "False layer4.1.sam.conv2.bias\n",
      "False layer4.1.sam.conv3.weight\n",
      "False layer4.1.sam.conv3.bias\n",
      "False layer4.1.sam.conv_w.0.weight\n",
      "False layer4.1.sam.conv_w.0.bias\n",
      "False layer4.1.sam.conv_w.2.weight\n",
      "False layer4.1.sam.conv_w.3.weight\n",
      "False layer4.1.sam.conv_w.3.bias\n",
      "False layer4.1.sam.conv_w.5.weight\n",
      "False layer4.1.sam.conv_w.5.bias\n",
      "False layer4.1.sam.conv_p.weight\n",
      "False layer4.1.sam.conv_p.bias\n",
      "False layer4.1.bn2.weight\n",
      "False layer4.1.bn2.bias\n",
      "False layer4.1.conv.weight\n",
      "False layer4.1.conv.bias\n",
      "False layer4.2.bn1.weight\n",
      "False layer4.2.bn1.bias\n",
      "False layer4.2.sam.conv1.weight\n",
      "False layer4.2.sam.conv1.bias\n",
      "False layer4.2.sam.conv2.weight\n",
      "False layer4.2.sam.conv2.bias\n",
      "False layer4.2.sam.conv3.weight\n",
      "False layer4.2.sam.conv3.bias\n",
      "False layer4.2.sam.conv_w.0.weight\n",
      "False layer4.2.sam.conv_w.0.bias\n",
      "False layer4.2.sam.conv_w.2.weight\n",
      "False layer4.2.sam.conv_w.3.weight\n",
      "False layer4.2.sam.conv_w.3.bias\n",
      "False layer4.2.sam.conv_w.5.weight\n",
      "False layer4.2.sam.conv_w.5.bias\n",
      "False layer4.2.sam.conv_p.weight\n",
      "False layer4.2.sam.conv_p.bias\n",
      "False layer4.2.bn2.weight\n",
      "False layer4.2.bn2.bias\n",
      "False layer4.2.conv.weight\n",
      "False layer4.2.conv.bias\n",
      "True fc.0.weight\n",
      "True fc.0.bias\n",
      "True fc.3.weight\n",
      "True fc.3.bias\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 20\n",
    "lr =1e-5\n",
    "nclasses = 40\n",
    "feature_tune=False\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "for parma in net.parameters():\n",
    "    parma.requires_grad = feature_tune\n",
    "for param in net.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "# # optimizer\n",
    "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=lr)\n",
    "# schedulr = torch.optim.lr_scheduler.StepLR(optimizer , step_size = 1 , gamma = 0.9)\n",
    "for name,param in net.named_parameters():\n",
    "    print(param.requires_grad, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: , lr = 1e-05\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c1a35576744c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mschedulr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschedulr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-fa883684184c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, num_epochs, optimizer, schedulr, device, nclasses)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch {}/{}: , lr = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# train step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mschedulr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-8f02bee059cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_func, optimizer, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# every 100 iteration, print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "schedulr = torch.optim.lr_scheduler.StepLR(optimizer , step_size = 1 , gamma = 0.8)\n",
    "fit(net, num_epochs, optimizer, schedulr,device, nclasses)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(dat, tar) in enumerate(test_dataloader):\n",
    "    print(i ,dat.shape, tar)\n",
    "    if ( i>30):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch':30 , 'state_dict':net.state_dict()}, '../baseSAN_chk0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
